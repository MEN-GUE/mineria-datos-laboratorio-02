---
title: "lab02"
output: html_document
date: "2026-02-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read csv
```{r load csv}
data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)
```

# 1.1
```{r summary}

library(dplyr)
library(tidyr)

# Excluímos id, textos, y variables de muy baja varianza (video)
movies_cluster <- data %>%
  select(budget, revenue, runtime, popularity, voteAvg, voteCount, 
         genresAmount, productionCoAmount, productionCountriesAmount, 
         actorsAmount, castWomenAmount, castMenAmount, releaseYear)

movies_cluster <- movies_cluster %>% 
  drop_na()

# Escalamiento 
movies_scaled <- as.data.frame(scale(movies_cluster))

# REsultado
summary(movies_scaled)
head(movies_scaled)
```

# Parte 2
# 1. Introducción

En esta sección se obtienen **reglas de asociación** utilizando el algoritmo **Apriori** sobre el conjunto de datos `movies_2026.csv`.

Se realiza:

* Discretización de variables numéricas.
* Generación de reglas con diferentes niveles de soporte y confianza.
* Evaluación del lift.
* Eliminación de variables muy frecuentes para obtener mejores insights.

---

# 2. Carga de Datos
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(arules)
library(arulesViz)
```

```{r}
movies <- read.csv("C:/Users/aleja/Downloads//data.csv", encoding = "latin1")
str(movies)
summary(movies)
```

---

# 3. Selección de Variables

Seleccionamos las variables relevantes para minería de reglas:

* genres
* originalLanguage
* budget
* revenue
* runtime
* popularity
* voteAvg
* voteCount

```{r}
movies2 <- movies %>%
  select(genres, originalLanguage, budget, revenue, runtime,
         popularity, voteAvg, voteCount) %>%
  drop_na(genres)
```

---

# 4. Discretización de Variables Numéricas

El algoritmo Apriori requiere variables categóricas. Se discretizan las variables numéricas usando cuantiles (3 categorías).

```{r}
movies2 <- movies2 %>%
  mutate(
    budget_cat = discretize(budget, method = "frequency", categories = 3),
    revenue_cat = discretize(revenue, method = "frequency", categories = 3),
    runtime_cat = discretize(runtime, method = "frequency", categories = 3),
    popularity_cat = discretize(popularity, method = "frequency", categories = 3),
    voteAvg_cat = discretize(voteAvg, method = "frequency", categories = 3),
    voteCount_cat = discretize(voteCount, method = "frequency", categories = 3)
  )

movies2 <- movies2 %>%
  select(genres, originalLanguage,
         budget_cat, revenue_cat, runtime_cat,
         popularity_cat, voteAvg_cat, voteCount_cat)
```

---

# 5. Conversión a Formato Transaccional

```{r}
movies_trans <- as(movies2, "transactions")
summary(movies_trans)
```

---

# 6. Generación de Reglas

## 6.1 Soporte = 0.05 | Confianza = 0.6

```{r}
rules1 <- apriori(movies_trans,
                  parameter = list(supp = 0.05,
                                   conf = 0.6,
                                   minlen = 2))

inspect(sort(rules1, by = "lift")[1:10])
```

### Discusión

Con soporte alto se generan pocas reglas y suelen estar dominadas por categorías frecuentes.

---

## 6.2 Soporte = 0.03 | Confianza = 0.7

```{r}
rules2 <- apriori(movies_trans,
                  parameter = list(supp = 0.03,
                                   conf = 0.7,
                                   minlen = 2))

inspect(sort(rules2, by = "lift")[1:10])
```

### Discusión

Se obtiene un mejor equilibrio entre cantidad y calidad de reglas.

---

## 6.3 Soporte = 0.01 | Confianza = 0.8

```{r}
rules3 <- apriori(movies_trans,
                  parameter = list(supp = 0.01,
                                   conf = 0.8,
                                   minlen = 2))

inspect(sort(rules3, by = "lift")[1:10])
```

### Discusión

Se generan muchas reglas. Aunque la confianza es alta, algunas pueden tener bajo soporte práctico.

---

# 7. Identificación de Ítems Muy Frecuentes

```{r}
itemFrequencyPlot(movies_trans, topN = 20, type = "absolute")
```

Es probable que el idioma inglés ("en") y categorías de bajo presupuesto o bajo revenue dominen las reglas.

---

# 8. Eliminación de Variable Muy Frecuente

Se elimina el idioma inglés para evaluar si emergen reglas más interesantes.

```{r}
movies3 <- movies2 %>%
  filter(originalLanguage != "en")

movies_trans2 <- as(movies3, "transactions")

rules_filtered <- apriori(movies_trans2,
                          parameter = list(supp = 0.02,
                                           conf = 0.7,
                                           minlen = 2))

inspect(sort(rules_filtered, by = "lift")[1:10])
```

### Discusión

Al eliminar una variable dominante:

* Se reduce el sesgo en las reglas.
* Aparecen asociaciones más específicas.
* Se obtienen mejores insights entre género, presupuesto, popularidad y votaciones.

---

# 9. Conclusiones

* La discretización es esencial para aplicar Apriori.
* El soporte controla la frecuencia mínima.
* La confianza mide la fuerza predictiva.
* El lift permite identificar asociaciones no triviales.
* Eliminar variables muy frecuentes mejora la calidad de los resultados.
* Un equilibrio adecuado (supp ≈ 0.02–0.03 y conf ≈ 0.7) genera reglas interpretables.

---

# 10. Visualización de Reglas

```{r}
plot(rules_filtered, method = "graph", engine = "htmlwidget")
```

# Parte 3
```{r paquetes y datos}
if(! "psych" %in% installed.packages()) install.packages("psych", depend = TRUE)
if(! "FactoMineR" %in% installed.packages()) install.packages("FactoMineR", depend = TRUE)
if(! "corrplot" %in% installed.packages()) install.packages("corrplot", depend = TRUE)
if(! "fpc" %in% installed.packages()) install.packages("fpc", depend = TRUE)
if(! "factoextra" %in% installed.packages()) install.packages("factoextra", depend = TRUE)
if(! "PCAmixdata" %in% installed.packages()) install.packages("PCAmixdata", depend = TRUE)
if(! "paran" %in% installed.packages()) install.packages("paran", depend = TRUE)

library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)

data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)

numeric_vars <- c("budget", "revenue", "runtime", "popularity",
                  "voteAvg", "voteCount", "genresAmount",
                  "productionCoAmount", "productionCountriesAmount",
                  "actorsAmount", "castWomenAmount", "castMenAmount")

categorical_vars <- c("genres", "originalLanguage", "video", "director",
                      "actors", "productionCompany", "productionCountry", "homePage")

numeric_vars_list <- paste(numeric_vars, collapse = ", ")
categorical_vars_list <- paste(categorical_vars, collapse = ", ")
```

## Descripción de los datos

El análisis se realizó sobre un conjunto de **`r format(nrow(data), big.mark = ",")`** películas obtenidas de la plataforma "The Movie DB".
A continuación, se describen las variables incluidas en el estudio:

------------------------------------------------------------------------

| **Variable** | **Descripción** |
|-----------------------------------|-------------------------------------|
| **id** | Identificador único de la película. |
| **popularity** | Índice de popularidad calculado semanalmente. |
| **budget** | Presupuesto de la película (en USD). |
| **revenue** | Ingresos generados por la película (en USD). |
| **runtime** | Duración de la película en minutos. |
| **voteAvg** | Promedio de votos en la plataforma. |
| **voteCount** | Número de votos recibidos. |
| **genresAmount** | Cantidad de géneros que representa la película. |
| **productionCoAmount** | Cantidad de compañías productoras involucradas. |
| **productionCountriesAmount** | Cantidad de países donde se rodó la película. |
| **actorsAmount** | Cantidad de actores en el elenco. |
| **castWomenAmount** | Cantidad de actrices en el elenco. |
| **castMenAmount** | Cantidad de actores masculinos en el elenco. |
| **releaseYear** | Año de lanzamiento. |

------------------------------------------------------------------------

### Variables numéricas seleccionadas para el PCA

Para el análisis de componentes principales se utilizarán **`r length(numeric_vars)` variables numéricas** que aportan información cuantitativa relevante sobre las películas: `r numeric_vars_list`.

Se excluyen:

-   **id**: Es un identificador único, no aporta información para el análisis.
-   **releaseYear**: Presenta muy poca variabilidad (la mayoría de registros pertenecen a años similares) y no contribuye a diferenciar entre películas.

```{r seleccion de variables numericas}
data_numeric <- data[, numeric_vars]

data_numeric <- na.omit(data_numeric)

str(data_numeric)
summary(data_numeric)
```

## 3.1 Transformación de variables categóricas para incluirlas en el PCA

Antes de proceder con el PCA, es necesario evaluar si vale la pena transformar las variables categóricas del dataset para incluirlas en el análisis.

### Variables categóricas del dataset

El dataset contiene **`r length(categorical_vars)` variables categóricas**: `r categorical_vars_list`.

-   **genres**: Géneros de la película, separados por `|`. Ejemplo: "Drama|Crime". Cada película puede tener múltiples géneros.
-   **originalLanguage**: Idioma original de la película (e.g., "en", "fa", "es").
-   **video**: Indica si tiene videos promocionales (TRUE/FALSE).
-   **director**: Director de la película.
-   **actors**: Elenco de la película, separado por `|`.
-   **productionCompany**: Compañías productoras.
-   **productionCountry**: Países de producción.
-   **homePage**: Página web de la película.

### Análisis de viabilidad

```{r cardinalidad categoricas}
cardinalidad <- sapply(categorical_vars, function(v) length(unique(data[[v]])))
data.frame(Variable = names(cardinalidad), Valores_Unicos = cardinalidad, row.names = NULL)

cat("\nDistribución de 'video':\n")
table(data$video)
```

### Opciones de transformación

1.  **One-Hot Encoding**: Consiste en crear una columna binaria por cada categoría. Sin embargo, variables como `director` y `actors` tienen miles de valores únicos, lo que generaría una matriz extremadamente dispersa y de altísima dimensionalidad, lo cual contradice el objetivo del PCA (reducir dimensiones).

2.  **Separación de géneros**: La variable `genres` podría separarse por `|` y codificarse como columnas binarias por género individual. Aunque es viable, esto añade múltiples columnas con baja frecuencia para géneros poco comunes.

3.  **PCAmixdata**: El paquete `PCAmixdata` permite realizar un PCA sobre datos mixtos (numéricos y categóricos). Sin embargo, requiere que las variables categóricas tengan una cantidad razonable de niveles. Con la cardinalidad observada en `director`, `actors` y `productionCompany`, el análisis sería computacionalmente costoso y los resultados difíciles de interpretar.

4.  **Variable `video`**: Aunque es trivialmente codificable como 0/1, tiene varianza cercana a cero porque casi todas las observaciones tienen el mismo valor (FALSE), por lo que no aportaría al PCA.

### Conclusión

**No vale la pena incluir las variables categóricas en el PCA.** Las razones principales son:

-   La altísima cardinalidad de variables como `director`, `actors` y `productionCompany` generaría una explosión dimensional.
-   Las variables con baja cardinalidad (`video`) tienen varianza casi nula.
-   El PCA está diseñado para capturar la variabilidad en variables continuas; las transformaciones binarias de categóricas producen matrices dispersas que dificultan la interpretación de los componentes.

Se procederá con las **`r length(numeric_vars)` variables numéricas** seleccionadas previamente.

## 3.2 ¿Es conveniente hacer un Análisis de Componentes Principales?

### 3.2.1 Determinante de la Matriz de Correlación

Lo primero que vamos a hacer es calcular el determinante de la matriz de correlación.
Si este es cercano a 0 significa que hay multicolinealidad, es decir, las variables están relacionadas entre sí.

```{r matriz de correlacion determinante}
rcor <- cor(data_numeric, use = "pairwise.complete.obs")
```

El determinante es: `r round(det(rcor), 6)`.

El valor obtenido (`r round(det(rcor), 6)`) es muy cercano a 0, lo que confirma la presencia de multicolinealidad entre las variables.
Esto significa que las variables numéricas comparten información redundante, lo cual es una condición favorable para aplicar PCA: el análisis buscará resumir esa redundancia en pocas componentes que capturen la mayor parte de la variabilidad.

### 3.2.2 KMO (Kaiser-Meyer-Olkin)

Se debe analizar si se puede usar el análisis factorial para formar las combinaciones lineales de las variables.
El índice KMO mide la adecuación muestral según la siguiente escala:

-   \< 0.5: Inaceptable
-   0.5 - 0.6: Miserable
-   0.6 - 0.7: Mediocre
-   0.7 - 0.8: Aceptable
-   0.8 - 0.9: Meritorio
-   \> 0.9: Excelente

```{r KMO}
resultado_kmo <- KMO(as.matrix(data_numeric))
resultado_kmo
```

El índice general obtenido (Overall MSA = `r round(resultado_kmo$MSA, 2)`) se clasifica como **meritorio**, lo que indica que los datos son adecuados para un análisis factorial.
Esto respalda fuertemente la aplicación de PCA.

Al examinar los valores MSA individuales por variable, se observa que la mayoría superan 0.8, lo que refuerza su inclusión.
Las variables `castMenAmount` (MSA = `r round(resultado_kmo$MSAi["castMenAmount"], 2)`) y `productionCountriesAmount` (MSA = `r round(resultado_kmo$MSAi["productionCountriesAmount"], 2)`) presentan los valores más bajos, en el umbral de lo aceptable, lo que sugiere que estas variables comparten menos estructura factorial con el resto.
No obstante, al estar por encima de 0.5, se mantienen en el análisis.

### 3.2.3 Test de Esfericidad de Bartlett

H0: La matriz de correlaciones es igual a la matriz identidad.\
Se busca rechazar la hipótesis nula de que la matriz de correlaciones es igual a la matriz identidad y por ende, que existe suficiente multicolinealidad entre las variables.
En una matriz de identidad la diagonal es 1, y los valores fuera de la diagonal son 0.
Esto implica que no hay más colinealidad entre las variables que la que hay entre cada variable consigo misma.

```{r Bartlett}
resultado_bartlett <- cortest.bartlett(data_numeric)
resultado_bartlett
```

El estadístico chi-cuadrado obtenido es `r format(round(resultado_bartlett$chisq, 1), big.mark = ",")` con `r resultado_bartlett$df` grados de libertad, y un valor p de `r resultado_bartlett$p.value`.
Al ser el valor p prácticamente 0 (mucho menor a 0.05), rechazamos H0 y concluimos que la matriz de correlaciones es significativamente diferente a la matriz identidad.
Esto confirma que existe suficiente multicolinealidad entre las variables y que el análisis factorial (y por tanto el PCA) es apropiado para estos datos.

En conjunto, tanto el determinante cercano a 0, el KMO meritorio (0.82) y el rechazo contundente de la prueba de Bartlett **confirman que es conveniente aplicar un Análisis de Componentes Principales** a este dataset.

### 3.2.4 Matriz de Correlación

A continuación se visualiza la matriz de correlación para identificar las relaciones más fuertes entre variables.

```{r corrplot}
matriz <- cor(data_numeric, use = "pairwise.complete.obs")
corrplot(matriz, method = "color", type = "upper", 
         tl.cex = 0.7, tl.col = "black",
         addCoef.col = "black", number.cex = 0.5)
```

En la matriz de correlación se pueden identificar varios patrones relevantes:

-   **`budget` y `revenue`** presentan una correlación positiva notable, lo cual es esperable: películas con mayor presupuesto tienden a generar mayores ingresos.
-   **`budget`, `revenue` y `voteCount`** forman un bloque correlacionado que refleja la dimensión comercial de las películas. `voteCount` se asocia con mayor visibilidad y presencia en la plataforma.
-   **`actorsAmount` y `castWomenAmount`** muestran correlación positiva, lo cual es lógico porque la cantidad de actrices es un subconjunto del elenco total. Sin embargo, `castMenAmount` presenta un comportamiento anómalo con correlaciones bajas respecto al resto de variables del elenco, posiblemente debido a valores extremos en esta variable (su media es desproporcionadamente alta respecto a la mediana, sugiriendo la presencia de outliers severos).
-   **`runtime`** se correlaciona moderadamente con `voteAvg`, `genresAmount` y `productionCoAmount`, lo que sugiere que las películas más largas tienden a ser producciones más complejas y mejor evaluadas.
-   **`popularity`** muestra correlaciones débiles con la mayoría de variables, lo que indica que es una métrica más independiente que depende de factores temporales y externos no capturados por las demás variables.
-   **`productionCountriesAmount`** tiene correlaciones bajas con el bloque financiero, lo que sugiere que la cantidad de países de producción no se relaciona linealmente con el éxito comercial.

## 3.3 Análisis de Componentes Principales

### 3.3.1 Ejecución del PCA

Para hacer el análisis de componentes principales es necesario normalizar los datos.
La función `prcomp` lo hace automáticamente con el parámetro `scale = TRUE`.

```{r PCA prcomp}
compPrinc <- prcomp(data_numeric, scale = TRUE)
compPrinc
```

El resumen del modelo es el siguiente:

```{r resumen PCA}
summary(compPrinc)
```

También ejecutamos el PCA con `FactoMineR::PCA()` para obtener información adicional:

```{r PCA FactoMineR}
compPrincPCA <- PCA(data_numeric, ncp = ncol(data_numeric), scale.unit = TRUE, graph = FALSE)
summary(compPrincPCA)
```

### Selección de Componentes

#### Regla de Kaiser

Los valores propios (eigenvalues) de cada componente son los siguientes:

```{r eigenvalues}
valores_propios <- compPrinc$sdev^2
nombres_pc <- paste0("PC", 1:length(valores_propios))
data.frame(Componente = nombres_pc, Valor_Propio = round(valores_propios, 4))
```

Según la regla de Kaiser, debemos quedarnos con los componentes que tienen valores propios mayores a 1.
Los componentes con valor propio menor a 1 explican menos varianza que una sola variable original estandarizada, por lo que no aportan información significativa.

En este caso, los primeros **3 componentes** cumplen la regla de Kaiser (PC1 = `r round(valores_propios[1], 2)`, PC2 = `r round(valores_propios[2], 2)`, PC3 = `r round(valores_propios[3], 2)`), mientras que PC4 (`r round(valores_propios[4], 2)`) ya cae por debajo de 1.

#### Gráfico de Sedimentación (Scree Plot)

El gráfico de sedimentación permite identificar visualmente el "codo" donde la varianza explicada por cada componente adicional comienza a estabilizarse.

```{r screeplot}
fviz_eig(compPrinc, addlabels = TRUE, ylim = c(0, 80))
fviz_eig(compPrinc, addlabels = TRUE, choice = c("eigenvalue"), ylim = c(0, 5))
```

El primer gráfico muestra el porcentaje de varianza explicada por cada componente, mientras que el segundo muestra los valores propios.
Se busca el punto donde la curva se estabiliza ("el codo"), lo que indica que los componentes adicionales ya no aportan información sustancial.

#### Porcentaje de Varianza Explicada

```{r varianza explicada}
summary(compPrinc)
```

Se busca retener suficientes componentes para explicar una proporción adecuada de la varianza total.

```{r tabla varianza}
varianza_tabla <- data.frame(
  Componente = paste0("PC", 1:length(valores_propios)),
  Valor_Propio = round(valores_propios, 4),
  Porcentaje_Varianza = round(valores_propios / sum(valores_propios) * 100, 2),
  Varianza_Acumulada = round(cumsum(valores_propios / sum(valores_propios) * 100), 2)
)
varianza_tabla
```

Con los primeros **3 componentes** (regla de Kaiser) se explica aproximadamente el **63.1%** de la varianza total.
Si se desea alcanzar al menos el **80%**, es necesario retener **6 componentes** (82.5% acumulado).
Existe un compromiso entre parsimonia (menos componentes, más fáciles de interpretar) y cobertura de varianza.
Para este análisis, se consideran los **3 primeros componentes** como los más relevantes por su interpretabilidad y por superar el umbral de Kaiser, aunque se reconoce que no capturan la totalidad de la variabilidad del dataset.

#### Prueba de Paralelismo (Horn's Parallel Analysis)

##### ¿Cómo funciona la Prueba de Paralelismo de Horn?

Se calculan los valores propios del PCA basado en los datos reales.
Se generan múltiples conjuntos de datos aleatorios con el mismo tamaño que los datos originales (mismo número de variables y observaciones).
Se realiza un PCA sobre los datos aleatorios y se extraen los valores propios esperados de cada componente.
Se comparan los valores propios reales con los esperados: Si un componente tiene un valor propio mayor que el de los datos simulados, significa que explica más varianza de la que se esperaría por azar, por lo que se retiene.
Si el valor propio es menor o igual al de los datos aleatorios, el componente no se retiene porque su explicación de varianza es insignificante.

En los resultados de esta prueba los valores simulados son los de la columna "Adjusted Eigenvalue" y los valores reales son "Unadjusted Eigenvalue".
Se retienen los componentes cuyo valor propio real sea mayor que el simulado.

```{r prueba de Horn}
paran(data_numeric, graph = TRUE)
```

### Carga Factorial Interpretativa

Se basa en la interpretación de los componentes.

En la siguiente gráfica se ilustra la calidad de la representación de las variables en las dos primeras dimensiones.

```{r grafico coseno}
fviz_pca_var(compPrinc, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE
)
```

**Interpretación del Gráfico de PCA:**

Representa la relación entre las variables originales proyectadas en el espacio de los dos primeros componentes principales (Dim1 y Dim2).
Vamos a analizarlo paso a paso.

1.  **Ejes del gráfico.** El Eje X (Dim1) representa el primer componente principal (PC1) y el Eje Y (Dim2) representa el segundo componente principal (PC2). Cada eje indica el porcentaje de varianza total que explica. En conjunto, los dos primeros componentes capturan una proporción de la variabilidad total de los datos.

2.  **Longitud de las Flechas (Vectores).** Cada flecha representa una variable original. La longitud de la flecha indica qué tan bien está representada la variable en el espacio de PC1 y PC2. Flechas largas indican que esas variables están bien representadas en los primeros dos componentes. Flechas cortas indican que la variable no está completamente explicada por PC1 y PC2 y puede necesitar más dimensiones para su interpretación.

3.  **Dirección de las Flechas.** Las variables con vectores apuntando en la misma dirección están correlacionadas positivamente. Las variables con vectores opuestos tienen una correlación negativa. Las variables con vectores perpendiculares (ángulo de 90°) están débilmente correlacionadas o no tienen relación.

4.  **Color de las Flechas (cos2 - Calidad de Representación).** El color indica el cos2, que mide la calidad de la representación de cada variable en el espacio de los componentes. Colores cálidos (rojo/naranja) representan variables bien explicadas por los primeros dos componentes (cos2 alto). Colores fríos (azul/verde) representan variables poco explicadas, lo que sugiere que necesitan más dimensiones para su correcta interpretación.

5.  **Relación con los Componentes Principales.** Se identifica qué variables tienen las cargas más altas en cada dimensión para interpretar conceptualmente qué representa cada componente.

### Biplot

El biplot combina la representación de las observaciones y las variables en el espacio de los componentes principales.

```{r biplot}
fviz_pca_biplot(compPrinc, repel = FALSE, 
                col.var = "#FC4E07",
                col.ind = "#00AFBB",
                alpha.ind = 0.1)
```

### Contribución de las variables a cada componente

Los siguientes gráficos muestran qué variables contribuyen más a cada una de las primeras tres dimensiones.
La línea roja discontinua representa la contribución esperada si todas las variables contribuyeran por igual.

```{r contribucion a las componentes}
fviz_contrib(compPrinc, choice = "var", axes = 1, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 2, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 3, top = 10)
```

### Calidad de representación (cos2) por variable y componente

El siguiente gráfico muestra la calidad de la representación de cada variable en cada componente.
Valores altos de cos2 indican que la variable está bien capturada por ese componente.

```{r cos2 corrplot}
var <- get_pca_var(compPrinc)
corrplot(var$cos2, is.corr = FALSE)
```

### Interpretación de las Componentes

Con base en los gráficos de contribución, las cargas factoriales y la calidad de representación, se interpretan los componentes retenidos.

```{r rotacion}
compPrinc$rotation
```

A partir de la matriz de rotación (loadings), se puede interpretar cada componente principal:

1.  **PC1 - Escala general de la película (38.2% de varianza).** Este componente presenta cargas positivas en prácticamente todas las variables: `actorsAmount` (0.39), `castWomenAmount` (0.36), `voteCount` (0.34), `budget` (0.34), `runtime` (0.33), `revenue` (0.32), `voteAvg` (0.32), `productionCoAmount` (0.28) y `genresAmount` (0.26). Es un componente de **tamaño o magnitud general**: películas con valores altos en PC1 son producciones grandes en todos los sentidos (mayor presupuesto, más ingresos, elencos más numerosos, mayor duración, más votos y mejor calificación). Las variables con menor peso son `popularity` (0.12) y `castMenAmount` (0.001), lo que indica que estas dos variables no se alinean con esta dimensión general. Es el patrón típico del primer componente en PCA, que captura la "escala" o "importancia" global del fenómeno.

2.  **PC2 - Producción internacional/artística vs. éxito comercial (13.9% de varianza).** Este componente contrasta dos perfiles de películas a través de cargas de signo opuesto. En el lado positivo: `productionCountriesAmount` (0.46), `castMenAmount` (0.39), `voteAvg` (0.30), `runtime` (0.25) — variables que describen producciones internacionales, con mayor duración y mejor evaluadas cualitativamente. En el lado negativo: `revenue` (-0.40), `budget` (-0.33), `voteCount` (-0.32) — variables que representan el éxito comercial medido en dinero y volumen de votos. Este componente diferencia entre **películas artísticas o de cine independiente/internacional** (rodadas en múltiples países, bien evaluadas pero con menor presupuesto) y **blockbusters comerciales** (alto presupuesto, altos ingresos, muchos votos pero no necesariamente mejor calificación).

3.  **PC3 - Estructura multinacional de producción (11.0% de varianza).** Dominado por cargas negativas fuertes en `castMenAmount` (-0.61) y `productionCountriesAmount` (-0.49), y una carga negativa moderada en `revenue` (-0.30). En el lado positivo, las cargas son más modestas: `productionCoAmount` (0.24), `genresAmount` (0.21). Este componente captura la dimensión de **producción multinacional con elencos masculinos grandes** en contraposición con **producciones con más compañías y diversidad de géneros**. La fuerte influencia de `castMenAmount` debe interpretarse con cautela dado los valores extremos observados en esta variable (media desproporcionada respecto a la mediana).

## Conclusiones

```{r resumen final}
varianza <- summary(compPrinc)
varianza
```

### Resumen de hallazgos

1.  **Viabilidad del PCA:** Las pruebas previas confirmaron la conveniencia de aplicar PCA. El determinante de la matriz de correlación cercano a 0 (`r round(det(rcor), 6)`) indica multicolinealidad. El índice KMO de `r round(resultado_kmo$MSA, 2)` (meritorio) y el rechazo contundente de la prueba de Bartlett (p-value = 0) respaldan la adecuación de los datos para el análisis factorial.

2.  **Dimensionalidad reducida:** Según la regla de Kaiser, se retienen **3 componentes principales** que explican el **63.1%** de la varianza total. Si se requiriera mayor cobertura (80%), serían necesarios 6 componentes. Las `r length(numeric_vars)` variables originales se resumen en 3 ejes decorrelacionados, facilitando el análisis.

3.  **Interpretabilidad de los componentes:**
    -   **PC1 (38.2%)** — **Escala general de la película**: captura la magnitud global de una producción (presupuesto, ingresos, elenco, duración, votos, calificación). Diferencia entre grandes producciones y películas pequeñas.
    -   **PC2 (13.9%)** — **Producción artística/internacional vs. comercial**: contrasta películas rodadas en múltiples países con buenas calificaciones pero menor presupuesto (perfil de cine independiente/artístico) contra blockbusters comerciales de alto presupuesto y altos ingresos.
    -   **PC3 (11.0%)** — **Estructura multinacional de producción**: captura la relación entre la cantidad de países de producción, la composición masculina del elenco y la diversidad de géneros/compañías.

4.  **Observaciones sobre la calidad de los datos:** La variable `castMenAmount` presenta valores extremos (media desproporcionada respecto a la mediana, con un máximo de 922,017) que afectan su comportamiento en el PCA. Esto se refleja en su MSA bajo (0.50) y su carga casi nula en PC1. Para futuros análisis, se recomienda investigar y tratar estos outliers antes de aplicar PCA.

5.  **Utilidad para modelos predictivos:** Al utilizar los componentes principales en lugar de las `r length(numeric_vars)` variables originales, se reduce la dimensionalidad, se eliminan problemas de multicolinealidad y se facilita la construcción de modelos de predicción futuros con variables decorrelacionadas.

6.  **Recomendaciones para CineVision Studios:**
    -   **Perfilamiento de películas:** Los tres componentes permiten ubicar cada película en un espacio tridimensional interpretable (escala general, perfil comercial vs. artístico, estructura de producción).
    -   **Segmentación estratégica:** CineVision Studios puede segmentar su catálogo según estos ejes para identificar nichos de mercado no explotados, por ejemplo, películas con alto potencial artístico (PC2 alto) pero baja visibilidad comercial.
    -   **Modelos predictivos:** Utilizar los scores de los componentes como variables de entrada para modelos de predicción de ingresos o popularidad, aprovechando que están decorrelacionados.
    -   **Limpieza de datos:** Antes de aplicar modelos avanzados, se recomienda revisar la variable `castMenAmount` y `productionCountriesAmount` para corregir posibles errores de registro.



