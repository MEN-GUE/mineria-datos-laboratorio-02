---
title: "lab02"
output:
  html_document: default
  pdf_document: default
date: "2026-02-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read csv
```{r load csv}
data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)
```

# 1.1
```{r summary}

library(dplyr)
library(tidyr)

# Excluímos id, textos, y variables de muy baja varianza (video)
movies_cluster <- data %>%
  select(budget, revenue, runtime, popularity, voteAvg, voteCount, 
         genresAmount, productionCoAmount, productionCountriesAmount, 
         actorsAmount, castWomenAmount, castMenAmount, releaseYear)

movies_cluster <- movies_cluster %>% 
  drop_na()

# Escalamiento 
movies_scaled <- as.data.frame(scale(movies_cluster))

# REsultado
summary(movies_scaled)
head(movies_scaled)
```

# 1.2
```{r hopkins-vat}
library(factoextra)
library(dplyr)

movies_sample <- movies_scaled %>% sample_n(1500)
tendencia <- get_clust_tendency(movies_sample, n = 50, graph = TRUE)

# --- RESULTADOS

# Hopkins
cat("Estadístico de Hopkins:", tendencia$hopkins_stat, "\n")

# VAT
print(tendencia$plot)
```
Podemos observar un valor estadístico de hopkins de 0.942, muy cercano 1, lo que indica cierta practicidad en realizar agrupaciones de datos, la prueba VAT también arroja cómo gráficamente los datos parecen mostrar ciertas tenedencias, detectamos al menos 4 grupos posibles separados, por lo que se puede proceder al clustering.

# 1.3
```{r metodos de evaluacion de agrupamiento futuro}
library(factoextra)
library(NbClust)
library(dplyr)
library(ggplot2)

set.seed(666)
movies_sample_opt <- movies_scaled %>% sample_n(1500)

# Metodo del codo
cat("Generando gráfica del Método del Codo...\n")
grafica_codo <- fviz_nbclust(movies_sample_opt, kmeans, method = "wss") +
  labs(title = "Método del Codo para determinar K óptimo",
       x = "Número de clústeres (k)", 
       y = "Suma de Cuadrados Intra-clúster (WSS)")

print(grafica_codo)

# Metodo nbclust
# Usamos invisible() y capture.output() para evitar que NbClust imprima demasiado texto en el PDF
cat("Ejecutando NbClust para evaluar 30 índices...\n")
invisible(capture.output(
  resultados_nbclust <- NbClust(data = movies_sample_opt, 
                                distance = "euclidean", 
                                min.nc = 2, max.nc = 10, 
                                method = "kmeans", 
                                index = "all")
))


votos <- as.data.frame(table(resultados_nbclust$Best.nc[1, ]))
colnames(votos) <- c("Clusters", "Frecuencia")

# Grafica
grafica_votos <- ggplot(votos, aes(x = Clusters, y = Frecuencia)) +
  geom_bar(stat = "identity", fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Número Óptimo de Clústeres - Votación Mayoritaria (NbClust)",
       x = "Número de clústeres (k) propuesto",
       y = "Frecuencia (Cantidad de índices)") +
  theme(plot.title = element_text(face = "bold"))

print(grafica_votos)
```
Las pruebas realizada con la ayuda de la libreria NbClust dan un por la regla de la mayoría una recomendación de agrupamiento mediante 4 clusters. Esto es apoyado por el método del codo, dónde gráficamente observamos un punto de inflección muy claro entre 3 y 4, debido a las pruebas de Nbcluts decidimos irnos por un total de 4 grupos.

# 1.4
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(factoextra)

set.seed(666)
indices_muestra <- sample(1:nrow(movies_cluster), 2000)

# Filtramos
movies_sample_cluster <- movies_cluster[indices_muestra, ]
movies_sample_scaled <- as.data.frame(scale(movies_sample_cluster))

# k-medias
km_res <- kmeans(movies_sample_scaled, centers = 4, nstart = 25)

movies_sample_cluster$Cluster_KMeans <- as.factor(km_res$cluster)

# jerarquico
cat("Calculando matriz de distancias para 2000 registros...\n")
distancias <- dist(movies_sample_scaled, method = "euclidean")

cat("Generando árbol jerárquico...\n")
hc_res <- hclust(distancias, method = "ward.D2")

grupos_hc <- cutree(hc_res, k = 4)
movies_sample_cluster$Cluster_HC <- as.factor(grupos_hc)

# comparacion
cat("\nMatriz de Confusión (K-Medias vs Jerárquico):\n")
tabla_comparacion <- table(K_Medias = movies_sample_cluster$Cluster_KMeans, 
                           Jerarquico = movies_sample_cluster$Cluster_HC)
print(tabla_comparacion)

# pca
grafico_pca <- fviz_cluster(km_res, data = movies_sample_scaled, 
                            geom = "point", 
                            ellipse.type = "convex", 
                            ggtheme = theme_minimal(),
                            main = "Agrupamiento K-Medias (Muestra 2000 obs)")
print(grafico_pca)

# grafico radar (mi favorito)
centroides_escalados <- movies_sample_scaled %>%
  mutate(Cluster = as.factor(km_res$cluster)) %>%
  group_by(Cluster) %>%
  summarise_all(mean)

centroides_largo <- centroides_escalados %>%
  pivot_longer(cols = -Cluster, names_to = "Variable", values_to = "Media_Escalada")

grafico_radar <- ggplot(centroides_largo, aes(x = Variable, y = Media_Escalada, color = Cluster, group = Cluster)) +
  geom_polygon(fill = NA, linewidth = 1) + 
  geom_point(size = 2) +
  geom_line(linewidth = 0.5, linetype = "dashed") +
  coord_polar() + 
  theme_minimal() +
  labs(title = "Perfil de los 4 Clusters (K-Medias en Muestra)",
       subtitle = "Valores estandarizados: 0 es el promedio de la variable",
       y = "Media Estandarizada") +
  theme(axis.text.x = element_text(angle = 0, size = 10, face = "bold"),
        legend.position = "right")

print(grafico_radar)
```
Podemos observar que ambos métodos de agrupamiento, tanto k-medias como jerárquico, muestran una tendencia similar en la asignación de registros a los clusters, aunque no son idénticos. La matriz de confusión revela que hay cierta superposición entre los grupos formados por ambos métodos, lo que sugiere que aunque no coinciden perfectamente, sí capturan patrones similares en los datos. El gráfico PCA muestra una clara separación entre los clusters formados por k-medias, mientras que el gráfico de radar  para este caso no es lo más eficiente para representar visualmente lo que están experimentando los datos.

# 1.5
```{r silueta kmeans}
library(cluster)
library(factoextra)

sil_kmeans <- silhouette(km_res$cluster, distancias)
cat("Coeficiente de silueta promedio (K-Medias):", mean(sil_kmeans[, 3]), "\n")
summary(sil_kmeans)
fviz_silhouette(sil_kmeans, 
                palette = "jco", 
                ggtheme = theme_minimal(),
                main = "Gráfico de Silueta - K-Medias (K=4)")
```

```{r silueta jerarquico}
sil_hc <- silhouette(grupos_hc, distancias)
cat("Coeficiente de silueta promedio (Jerárquico):", mean(sil_hc[, 3]), "\n")
summary(sil_hc)
fviz_silhouette(sil_hc, 
                palette = "jco", 
                ggtheme = theme_minimal(),
                main = "Gráfico de Silueta - Jerárquico Ward.D2 (K=4)")
```

### Comparación de calidad y selección del algoritmo

```{r comparacion silueta}
comparacion_silueta <- data.frame(
  Algoritmo = c("K-Medias", "Jerárquico (Ward.D2)"),
  Silueta_Promedio = c(round(mean(sil_kmeans[, 3]), 4), round(mean(sil_hc[, 3]), 4))
)
kable(comparacion_silueta, format = "markdown",
      caption = "Comparación de Calidad de Agrupamiento")
```

Al comparar ambos algoritmos mediante el coeficiente de silueta promedio, se puede determinar cuál produce grupos más cohesivos y mejor separados.
Un valor de silueta más alto indica que las observaciones están mejor asignadas a sus respectivos clusters.

El análisis de silueta para **K-Medias** muestra un promedio general positivo, lo que confirma que la mayoría de las películas comparten características fuertes con su propio segmento y se diferencian adecuadamente de los demás.
El análisis para el **clustering jerárquico** también produce grupos coherentes, aunque la distribución de siluetas puede diferir.

Aunque se observan algunas películas con valores negativos en ambos métodos, esto es esperable ya que representan producciones "fronterizas" que mezclan atributos de distintos grupos.

**Decisión:** Se selecciona el algoritmo con mayor coeficiente de silueta promedio para la exploración e interpretación de los grupos, ya que produce agrupaciones de mayor calidad.
En lo sucesivo, se utilizará **K-Medias** para el análisis detallado de los perfiles de cada cluster.

# 1.6

## Medidas de tendencia central por cluster

Para interpretar los grupos se analizan las medidas de tendencia central (media y mediana) de todas las variables continuas utilizadas en el agrupamiento.
La mediana es especialmente útil cuando existen valores extremos que pueden distorsionar la media.

```{r perfil medias}
library(dplyr)
library(knitr)

perfil_medias <- movies_sample_cluster %>%
  group_by(Cluster_KMeans) %>%
  summarise(
    n = n(),
    budget_media = mean(budget, na.rm = TRUE),
    revenue_media = mean(revenue, na.rm = TRUE),
    runtime_media = mean(runtime, na.rm = TRUE),
    popularity_media = mean(popularity, na.rm = TRUE),
    voteAvg_media = mean(voteAvg, na.rm = TRUE),
    voteCount_media = mean(voteCount, na.rm = TRUE),
    genresAmount_media = mean(genresAmount, na.rm = TRUE),
    productionCoAmount_media = mean(productionCoAmount, na.rm = TRUE),
    productionCountriesAmount_media = mean(productionCountriesAmount, na.rm = TRUE),
    actorsAmount_media = mean(actorsAmount, na.rm = TRUE),
    castWomenAmount_media = mean(castWomenAmount, na.rm = TRUE),
    castMenAmount_media = mean(castMenAmount, na.rm = TRUE),
    releaseYear_media = mean(releaseYear, na.rm = TRUE)
  )

kable(perfil_medias, format = "markdown", digits = 2,
      caption = "Medias de todas las variables por Cluster")
```

```{r perfil medianas}
perfil_medianas <- movies_sample_cluster %>%
  group_by(Cluster_KMeans) %>%
  summarise(
    n = n(),
    budget_mediana = median(budget, na.rm = TRUE),
    revenue_mediana = median(revenue, na.rm = TRUE),
    runtime_mediana = median(runtime, na.rm = TRUE),
    popularity_mediana = median(popularity, na.rm = TRUE),
    voteAvg_mediana = median(voteAvg, na.rm = TRUE),
    voteCount_mediana = median(voteCount, na.rm = TRUE),
    genresAmount_mediana = median(genresAmount, na.rm = TRUE),
    productionCoAmount_mediana = median(productionCoAmount, na.rm = TRUE),
    productionCountriesAmount_mediana = median(productionCountriesAmount, na.rm = TRUE),
    actorsAmount_mediana = median(actorsAmount, na.rm = TRUE),
    castWomenAmount_mediana = median(castWomenAmount, na.rm = TRUE),
    castMenAmount_mediana = median(castMenAmount, na.rm = TRUE),
    releaseYear_mediana = median(releaseYear, na.rm = TRUE)
  )

kable(perfil_medianas, format = "markdown", digits = 2,
      caption = "Medianas de todas las variables por Cluster")
```

Las medias y medianas permiten identificar el "centro" de cada grupo.
Cuando media y mediana difieren mucho (como ocurre en `budget` y `revenue`), indica la presencia de valores extremos dentro del cluster.
Esto es importante para no sobreestimar el presupuesto o ingresos "típicos" de un grupo.

## Tablas de frecuencia de variables categóricas por cluster

Para complementar el análisis con variables categóricas, se incorporan al dataframe de la muestra las variables `originalLanguage` y `genres` del dataset original.
Esto permite observar qué idiomas y géneros predominan en cada cluster.

```{r categoricas por cluster}
movies_sample_cluster$originalLanguage <- data$originalLanguage[indices_muestra]
movies_sample_cluster$genres <- data$genres[indices_muestra]

cat("=== Frecuencia de idioma original por Cluster ===\n\n")
for (cl in sort(unique(movies_sample_cluster$Cluster_KMeans))) {
  cat(paste0("--- Cluster ", cl, " ---\n"))
  freq <- sort(table(movies_sample_cluster$originalLanguage[movies_sample_cluster$Cluster_KMeans == cl]),
               decreasing = TRUE)
  print(head(freq, 10))
  cat("\n")
}
```

```{r generos por cluster}
library(tidyr)

generos_split <- movies_sample_cluster %>%
  select(Cluster_KMeans, genres) %>%
  separate_rows(genres, sep = "\\|") %>%
  filter(genres != "")

cat("=== Top 10 géneros por Cluster ===\n\n")
for (cl in sort(unique(generos_split$Cluster_KMeans))) {
  cat(paste0("--- Cluster ", cl, " ---\n"))
  freq <- sort(table(generos_split$genres[generos_split$Cluster_KMeans == cl]),
               decreasing = TRUE)
  print(head(freq, 10))
  cat("\n")
}
```

Las tablas de frecuencia de idioma revelan si un cluster concentra producciones en un idioma específico (por ejemplo, si el cine comercial exitoso está dominado por el inglés), mientras que la distribución de géneros permite entender el perfil temático de cada grupo.

## Interpretación de los grupos

Con base en las medidas de tendencia central y las tablas de frecuencia, se interpretan los cuatro clusters:

* **Grupo 1 (Cortometrajes o Amateur):** Proyectos de muy corta duración, con presupuestos, elencos y ganancias prácticamente nulos. La mediana de `budget` y `revenue` cercana a 0 confirma que no son producciones comerciales. Suelen tener pocos géneros asignados y pocas compañías productoras.

* **Grupo 2 (Épicas Aclamadas):** Producciones de larga duración con elencos numerosos que logran las mejores calificaciones del público. La media de `actorsAmount` es significativamente mayor que en otros clusters, y el `voteAvg` es el más alto. Esto sugiere que son películas con producción elaborada y reconocimiento de calidad.

* **Grupo 3 (Cine Independiente):** Películas de duración tradicional pero con presupuesto mínimo. Generan poco dinero pero atraen a nichos específicos. La mediana de `budget` es baja, pero la duración es comparable al cine comercial, lo que indica producciones modestas pero completas.

* **Grupo 4 (Cine Comercial Exitoso):** Es el estándar rentable de la industria: películas populares, de duración estándar y con buenos ingresos. Concentran los presupuestos y recaudaciones más altas. Las tablas de frecuencia de idioma probablemente muestran predominio del inglés, y los géneros más frecuentes son los de mayor atractivo masivo (Drama, Action, Comedy).

# Parte 2
# 1. Introducción

En esta sección se obtienen **reglas de asociación** utilizando el algoritmo **Apriori** sobre el conjunto de datos `movies_2026.csv`.

Se realiza:

* Discretización de variables numéricas.
* Generación de reglas con diferentes niveles de soporte y confianza.
* Evaluación del lift.
* Eliminación de variables muy frecuentes para obtener mejores insights.

---

# 2. Carga de Datos
```{r}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(arules)
library(arulesViz)
```

```{r}
movies <- read.csv("movies_2026.csv", encoding = "latin1")
str(movies)
summary(movies)
```

---

# 3. Selección de Variables

Seleccionamos las variables relevantes para minería de reglas:

* genres
* originalLanguage
* budget
* revenue
* runtime
* popularity
* voteAvg
* voteCount

```{r}
movies2 <- movies %>%
  select(genres, originalLanguage, budget, revenue, runtime,
         popularity, voteAvg, voteCount) %>%
  drop_na(genres)
```

---

# 4. Discretización de Variables Numéricas

El algoritmo Apriori requiere variables categóricas. Se discretizan las variables numéricas usando cuantiles (3 categorías).

```{r}
movies2 <- movies2 %>%
  mutate(
    budget_cat = discretize(budget, method = "frequency", categories = 3),
    revenue_cat = discretize(revenue, method = "frequency", categories = 3),
    runtime_cat = discretize(runtime, method = "frequency", categories = 3),
    popularity_cat = discretize(popularity, method = "frequency", categories = 3),
    voteAvg_cat = discretize(voteAvg, method = "frequency", categories = 3),
    voteCount_cat = discretize(voteCount, method = "frequency", categories = 3)
  )

movies2 <- movies2 %>%
  select(genres, originalLanguage,
         budget_cat, revenue_cat, runtime_cat,
         popularity_cat, voteAvg_cat, voteCount_cat)
```

---

# 5. Conversión a Formato Transaccional

```{r}
movies_trans <- as(movies2, "transactions")
summary(movies_trans)
```

---

# 6. Generación de Reglas

## 6.1 Soporte = 0.05 | Confianza = 0.6

```{r reglas1}
rules1 <- apriori(movies_trans,
                  parameter = list(supp = 0.05,
                                   conf = 0.6,
                                   minlen = 2))

cat("Total de reglas generadas:", length(rules1), "\n\n")
inspect(sort(rules1, by = "lift")[1:min(10, length(rules1))])
```

### Discusión

Con soporte = 0.05 y confianza = 0.6 se obtiene un número reducido de reglas.
Al exigir que al menos el 5% de las transacciones contengan los ítems, las reglas resultantes reflejan patrones muy frecuentes en el dataset.
Esto significa que las reglas están dominadas por categorías omnipresentes como el idioma inglés o los rangos más bajos de presupuesto y revenue.
El **lift** de las reglas indica cuánto más probable es la asociación respecto a lo esperado por azar: un lift > 1 indica una asociación positiva, y mientras más alto, más fuerte e interesante es la regla.

---

## 6.2 Soporte = 0.03 | Confianza = 0.7

```{r reglas2}
rules2 <- apriori(movies_trans,
                  parameter = list(supp = 0.03,
                                   conf = 0.7,
                                   minlen = 2))

cat("Total de reglas generadas:", length(rules2), "\n\n")
inspect(sort(rules2, by = "lift")[1:min(10, length(rules2))])
```

### Discusión

Al reducir el soporte a 0.03 y aumentar la confianza a 0.7, se logra un mejor equilibrio entre cantidad y calidad de reglas.
Se generan más reglas que en el caso anterior, permitiendo descubrir asociaciones menos frecuentes pero con mayor poder predictivo.
Las reglas con mayor lift en este escenario revelan asociaciones más interesantes entre las variables discretizadas.
Por ejemplo, reglas que asocian rangos altos de presupuesto con rangos altos de ingresos y cantidad de votos reflejan el patrón esperable de la industria: las grandes inversiones generan grandes retornos y mayor visibilidad.
Las reglas con lift más alto son las más relevantes, ya que representan asociaciones que ocurren significativamente más de lo esperado por azar.

---

## 6.3 Soporte = 0.01 | Confianza = 0.8

```{r reglas3}
rules3 <- apriori(movies_trans,
                  parameter = list(supp = 0.01,
                                   conf = 0.8,
                                   minlen = 2))

cat("Total de reglas generadas:", length(rules3), "\n\n")
inspect(sort(rules3, by = "lift")[1:min(10, length(rules3))])
```

### Discusión

Con soporte = 0.01 y confianza = 0.8 se genera la mayor cantidad de reglas de los tres escenarios.
La alta confianza (80%) garantiza que las reglas tienen un fuerte poder predictivo: cuando aparece el antecedente, el consecuente ocurre en al menos el 80% de los casos.
Sin embargo, el soporte bajo (1%) significa que algunas reglas aplican a un número muy pequeño de películas, lo que puede limitar su utilidad práctica.
Las reglas con lift más alto en este escenario tienden a ser las más específicas y reveladores, mostrando asociaciones entre combinaciones de rangos de variables que no son evidentes a simple vista.
Es importante priorizar reglas que combinen alto lift con soporte razonable para obtener hallazgos accionables.

---

# 7. Identificación de Ítems Muy Frecuentes

```{r}
itemFrequencyPlot(movies_trans, topN = 20, type = "absolute")
```

Es probable que el idioma inglés ("en") y categorías de bajo presupuesto o bajo revenue dominen las reglas.

---

# 8. Eliminación de Variable Muy Frecuente

Se elimina el idioma inglés para evaluar si emergen reglas más interesantes.

```{r}
movies3 <- movies2 %>%
  filter(originalLanguage != "en")

movies_trans2 <- as(movies3, "transactions")

rules_filtered <- apriori(movies_trans2,
                          parameter = list(supp = 0.02,
                                           conf = 0.7,
                                           minlen = 2))

inspect(sort(rules_filtered, by = "lift")[1:10])
```

### Discusión

Al eliminar el idioma inglés (la categoría más frecuente en `originalLanguage`), se logran cambios significativos:

* **Se reduce el sesgo** que imponía la omnipresencia del inglés, que aparecía en la mayoría de las reglas previas sin aportar información diferenciadora.
* **Emergen asociaciones más específicas** entre los idiomas restantes y las variables de producción. Por ejemplo, pueden aparecer reglas que asocien idiomas como el francés o el japonés con rangos específicos de presupuesto o calificación, revelando patrones de mercados cinematográficos específicos.
* Las reglas con mayor lift en este subconjunto filtrado son las más interesantes para CineVision Studios, ya que muestran patrones no evidentes que la dominancia del inglés ocultaba.

Esta decisión de eliminar ítems muy frecuentes es una práctica estándar en minería de reglas de asociación: los ítems que aparecen en casi todas las transacciones generan reglas triviales con alto soporte pero bajo valor informativo.

---

# 9. Conclusiones de Reglas de Asociación

```{r resumen reglas}
cat("Resumen de reglas generadas por escenario:\n")
cat("  Soporte=0.05, Confianza=0.6:", length(rules1), "reglas\n")
cat("  Soporte=0.03, Confianza=0.7:", length(rules2), "reglas\n")
cat("  Soporte=0.01, Confianza=0.8:", length(rules3), "reglas\n")
cat("  Filtrado (sin inglés), Soporte=0.02, Confianza=0.7:", length(rules_filtered), "reglas\n")
```

**Hallazgos principales:**

* La **discretización** de variables numéricas en 3 categorías (por cuantiles) fue esencial para convertir las variables continuas al formato categórico requerido por Apriori.
* El **soporte** controla la frecuencia mínima: valores altos (0.05) generan pocas reglas muy generales, mientras que valores bajos (0.01) producen muchas reglas más específicas.
* La **confianza** mide la fuerza predictiva de cada regla: con confianza 0.8, las reglas encontradas tienen un poder predictivo alto.
* El **lift** es la métrica más importante para identificar asociaciones no triviales. Reglas con lift significativamente mayor a 1 representan patrones que ocurren mucho más de lo esperado por azar.
* **Eliminar el idioma inglés** (variable dominante) fue clave para descubrir patrones ocultos entre géneros, presupuesto, popularidad y votaciones en mercados cinematográficos no angloparlantes.
* El equilibrio óptimo para este dataset se encuentra con **soporte entre 0.02-0.03 y confianza de 0.7**, que genera reglas interpretables y accionables sin ser ni demasiado genéricas ni demasiado específicas.

---

# 10. Visualización de Reglas

```{r}
plot(rules_filtered, method = "graph", engine = "htmlwidget")
```

# Parte 3
```{r paquetes y datos}
if(! "psych" %in% installed.packages()) install.packages("psych", depend = TRUE)
if(! "FactoMineR" %in% installed.packages()) install.packages("FactoMineR", depend = TRUE)
if(! "corrplot" %in% installed.packages()) install.packages("corrplot", depend = TRUE)
if(! "fpc" %in% installed.packages()) install.packages("fpc", depend = TRUE)
if(! "factoextra" %in% installed.packages()) install.packages("factoextra", depend = TRUE)
if(! "PCAmixdata" %in% installed.packages()) install.packages("PCAmixdata", depend = TRUE)
if(! "paran" %in% installed.packages()) install.packages("paran", depend = TRUE)

library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)

data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)

numeric_vars <- c("budget", "revenue", "runtime", "popularity",
                  "voteAvg", "voteCount", "genresAmount",
                  "productionCoAmount", "productionCountriesAmount",
                  "actorsAmount", "castWomenAmount", "castMenAmount")

categorical_vars <- c("genres", "originalLanguage", "video", "director",
                      "actors", "productionCompany", "productionCountry", "homePage")

numeric_vars_list <- paste(numeric_vars, collapse = ", ")
categorical_vars_list <- paste(categorical_vars, collapse = ", ")
```

## Descripción de los datos

El análisis se realizó sobre un conjunto de **`r format(nrow(data), big.mark = ",")`** películas obtenidas de la plataforma "The Movie DB".
A continuación, se describen las variables incluidas en el estudio:

------------------------------------------------------------------------

| **Variable** | **Descripción** |
|-----------------------------------|-------------------------------------|
| **id** | Identificador único de la película. |
| **popularity** | Índice de popularidad calculado semanalmente. |
| **budget** | Presupuesto de la película (en USD). |
| **revenue** | Ingresos generados por la película (en USD). |
| **runtime** | Duración de la película en minutos. |
| **voteAvg** | Promedio de votos en la plataforma. |
| **voteCount** | Número de votos recibidos. |
| **genresAmount** | Cantidad de géneros que representa la película. |
| **productionCoAmount** | Cantidad de compañías productoras involucradas. |
| **productionCountriesAmount** | Cantidad de países donde se rodó la película. |
| **actorsAmount** | Cantidad de actores en el elenco. |
| **castWomenAmount** | Cantidad de actrices en el elenco. |
| **castMenAmount** | Cantidad de actores masculinos en el elenco. |
| **releaseYear** | Año de lanzamiento. |

------------------------------------------------------------------------

### Variables numéricas seleccionadas para el PCA

Para el análisis de componentes principales se utilizarán **`r length(numeric_vars)` variables numéricas** que aportan información cuantitativa relevante sobre las películas: `r numeric_vars_list`.

Se excluyen:

-   **id**: Es un identificador único, no aporta información para el análisis.
-   **releaseYear**: Presenta muy poca variabilidad (la mayoría de registros pertenecen a años similares) y no contribuye a diferenciar entre películas.

```{r seleccion de variables numericas}
data_numeric <- data[, numeric_vars]

data_numeric <- na.omit(data_numeric)

str(data_numeric)
summary(data_numeric)
```

## 3.1 Transformación de variables categóricas para incluirlas en el PCA

Antes de proceder con el PCA, es necesario evaluar si vale la pena transformar las variables categóricas del dataset para incluirlas en el análisis.

### Variables categóricas del dataset

El dataset contiene **`r length(categorical_vars)` variables categóricas**: `r categorical_vars_list`.

-   **genres**: Géneros de la película, separados por `|`. Ejemplo: "Drama|Crime". Cada película puede tener múltiples géneros.
-   **originalLanguage**: Idioma original de la película (e.g., "en", "fa", "es").
-   **video**: Indica si tiene videos promocionales (TRUE/FALSE).
-   **director**: Director de la película.
-   **actors**: Elenco de la película, separado por `|`.
-   **productionCompany**: Compañías productoras.
-   **productionCountry**: Países de producción.
-   **homePage**: Página web de la película.

### Análisis de viabilidad

```{r cardinalidad categoricas}
cardinalidad <- sapply(categorical_vars, function(v) length(unique(data[[v]])))
data.frame(Variable = names(cardinalidad), Valores_Unicos = cardinalidad, row.names = NULL)

cat("\nDistribución de 'video':\n")
table(data$video)
```

### Opciones de transformación

1.  **One-Hot Encoding**: Consiste en crear una columna binaria por cada categoría. Sin embargo, variables como `director` y `actors` tienen miles de valores únicos, lo que generaría una matriz extremadamente dispersa y de altísima dimensionalidad, lo cual contradice el objetivo del PCA (reducir dimensiones).

2.  **Separación de géneros**: La variable `genres` podría separarse por `|` y codificarse como columnas binarias por género individual. Aunque es viable, esto añade múltiples columnas con baja frecuencia para géneros poco comunes.

3.  **PCAmixdata**: El paquete `PCAmixdata` permite realizar un PCA sobre datos mixtos (numéricos y categóricos). Sin embargo, requiere que las variables categóricas tengan una cantidad razonable de niveles. Con la cardinalidad observada en `director`, `actors` y `productionCompany`, el análisis sería computacionalmente costoso y los resultados difíciles de interpretar.

4.  **Variable `video`**: Aunque es trivialmente codificable como 0/1, tiene varianza cercana a cero porque casi todas las observaciones tienen el mismo valor (FALSE), por lo que no aportaría al PCA.

### Conclusión

**No vale la pena incluir las variables categóricas en el PCA.** Las razones principales son:

-   La altísima cardinalidad de variables como `director`, `actors` y `productionCompany` generaría una explosión dimensional.
-   Las variables con baja cardinalidad (`video`) tienen varianza casi nula.
-   El PCA está diseñado para capturar la variabilidad en variables continuas; las transformaciones binarias de categóricas producen matrices dispersas que dificultan la interpretación de los componentes.

Se procederá con las **`r length(numeric_vars)` variables numéricas** seleccionadas previamente.

## 3.2 ¿Es conveniente hacer un Análisis de Componentes Principales?

### 3.2.1 Determinante de la Matriz de Correlación

Lo primero que vamos a hacer es calcular el determinante de la matriz de correlación.
Si este es cercano a 0 significa que hay multicolinealidad, es decir, las variables están relacionadas entre sí.

```{r matriz de correlacion determinante}
rcor <- cor(data_numeric, use = "pairwise.complete.obs")
```

El determinante es: `r round(det(rcor), 6)`.

El valor obtenido (`r round(det(rcor), 6)`) es muy cercano a 0, lo que confirma la presencia de multicolinealidad entre las variables.
Esto significa que las variables numéricas comparten información redundante, lo cual es una condición favorable para aplicar PCA: el análisis buscará resumir esa redundancia en pocas componentes que capturen la mayor parte de la variabilidad.

### 3.2.2 KMO (Kaiser-Meyer-Olkin)

Se debe analizar si se puede usar el análisis factorial para formar las combinaciones lineales de las variables.
El índice KMO mide la adecuación muestral según la siguiente escala:

-   \< 0.5: Inaceptable
-   0.5 - 0.6: Miserable
-   0.6 - 0.7: Mediocre
-   0.7 - 0.8: Aceptable
-   0.8 - 0.9: Meritorio
-   \> 0.9: Excelente

```{r KMO}
resultado_kmo <- KMO(as.matrix(data_numeric))
resultado_kmo
```

El índice general obtenido (Overall MSA = `r round(resultado_kmo$MSA, 2)`) se clasifica como **meritorio**, lo que indica que los datos son adecuados para un análisis factorial.
Esto respalda fuertemente la aplicación de PCA.

Al examinar los valores MSA individuales por variable, se observa que la mayoría superan 0.8, lo que refuerza su inclusión.
Las variables `castMenAmount` (MSA = `r round(resultado_kmo$MSAi["castMenAmount"], 2)`) y `productionCountriesAmount` (MSA = `r round(resultado_kmo$MSAi["productionCountriesAmount"], 2)`) presentan los valores más bajos, en el umbral de lo aceptable, lo que sugiere que estas variables comparten menos estructura factorial con el resto.
No obstante, al estar por encima de 0.5, se mantienen en el análisis.

### 3.2.3 Test de Esfericidad de Bartlett

H0: La matriz de correlaciones es igual a la matriz identidad.\
Se busca rechazar la hipótesis nula de que la matriz de correlaciones es igual a la matriz identidad y por ende, que existe suficiente multicolinealidad entre las variables.
En una matriz de identidad la diagonal es 1, y los valores fuera de la diagonal son 0.
Esto implica que no hay más colinealidad entre las variables que la que hay entre cada variable consigo misma.

```{r Bartlett}
resultado_bartlett <- cortest.bartlett(data_numeric)
resultado_bartlett
```

El estadístico chi-cuadrado obtenido es `r format(round(resultado_bartlett$chisq, 1), big.mark = ",")` con `r resultado_bartlett$df` grados de libertad, y un valor p de `r resultado_bartlett$p.value`.
Al ser el valor p prácticamente 0 (mucho menor a 0.05), rechazamos H0 y concluimos que la matriz de correlaciones es significativamente diferente a la matriz identidad.
Esto confirma que existe suficiente multicolinealidad entre las variables y que el análisis factorial (y por tanto el PCA) es apropiado para estos datos.

En conjunto, tanto el determinante cercano a 0, el KMO meritorio (0.82) y el rechazo contundente de la prueba de Bartlett **confirman que es conveniente aplicar un Análisis de Componentes Principales** a este dataset.

### 3.2.4 Matriz de Correlación

A continuación se visualiza la matriz de correlación para identificar las relaciones más fuertes entre variables.

```{r corrplot}
matriz <- cor(data_numeric, use = "pairwise.complete.obs")
corrplot(matriz, method = "color", type = "upper", 
         tl.cex = 0.7, tl.col = "black",
         addCoef.col = "black", number.cex = 0.5)
```

En la matriz de correlación se pueden identificar varios patrones relevantes:

-   **`budget` y `revenue`** presentan una correlación positiva notable, lo cual es esperable: películas con mayor presupuesto tienden a generar mayores ingresos.
-   **`budget`, `revenue` y `voteCount`** forman un bloque correlacionado que refleja la dimensión comercial de las películas. `voteCount` se asocia con mayor visibilidad y presencia en la plataforma.
-   **`actorsAmount` y `castWomenAmount`** muestran correlación positiva, lo cual es lógico porque la cantidad de actrices es un subconjunto del elenco total. Sin embargo, `castMenAmount` presenta un comportamiento anómalo con correlaciones bajas respecto al resto de variables del elenco, posiblemente debido a valores extremos en esta variable (su media es desproporcionadamente alta respecto a la mediana, sugiriendo la presencia de outliers severos).
-   **`runtime`** se correlaciona moderadamente con `voteAvg`, `genresAmount` y `productionCoAmount`, lo que sugiere que las películas más largas tienden a ser producciones más complejas y mejor evaluadas.
-   **`popularity`** muestra correlaciones débiles con la mayoría de variables, lo que indica que es una métrica más independiente que depende de factores temporales y externos no capturados por las demás variables.
-   **`productionCountriesAmount`** tiene correlaciones bajas con el bloque financiero, lo que sugiere que la cantidad de países de producción no se relaciona linealmente con el éxito comercial.

## 3.3 Análisis de Componentes Principales

### 3.3.1 Ejecución del PCA

Para hacer el análisis de componentes principales es necesario normalizar los datos.
La función `prcomp` lo hace automáticamente con el parámetro `scale = TRUE`.

```{r PCA prcomp}
compPrinc <- prcomp(data_numeric, scale = TRUE)
compPrinc
```

El resumen del modelo es el siguiente:

```{r resumen PCA}
summary(compPrinc)
```

También ejecutamos el PCA con `FactoMineR::PCA()` para obtener información adicional:

```{r PCA FactoMineR}
compPrincPCA <- PCA(data_numeric, ncp = ncol(data_numeric), scale.unit = TRUE, graph = FALSE)
summary(compPrincPCA)
```

### Selección de Componentes

#### Regla de Kaiser

Los valores propios (eigenvalues) de cada componente son los siguientes:

```{r eigenvalues}
valores_propios <- compPrinc$sdev^2
nombres_pc <- paste0("PC", 1:length(valores_propios))
data.frame(Componente = nombres_pc, Valor_Propio = round(valores_propios, 4))
```

Según la regla de Kaiser, debemos quedarnos con los componentes que tienen valores propios mayores a 1.
Los componentes con valor propio menor a 1 explican menos varianza que una sola variable original estandarizada, por lo que no aportan información significativa.

En este caso, los primeros **3 componentes** cumplen la regla de Kaiser (PC1 = `r round(valores_propios[1], 2)`, PC2 = `r round(valores_propios[2], 2)`, PC3 = `r round(valores_propios[3], 2)`), mientras que PC4 (`r round(valores_propios[4], 2)`) ya cae por debajo de 1.

#### Gráfico de Sedimentación (Scree Plot)

El gráfico de sedimentación permite identificar visualmente el "codo" donde la varianza explicada por cada componente adicional comienza a estabilizarse.

```{r screeplot}
fviz_eig(compPrinc, addlabels = TRUE, ylim = c(0, 80))
fviz_eig(compPrinc, addlabels = TRUE, choice = c("eigenvalue"), ylim = c(0, 5))
```

El primer gráfico muestra el porcentaje de varianza explicada por cada componente, mientras que el segundo muestra los valores propios.
Se busca el punto donde la curva se estabiliza ("el codo"), lo que indica que los componentes adicionales ya no aportan información sustancial.

#### Porcentaje de Varianza Explicada

```{r varianza explicada}
summary(compPrinc)
```

Se busca retener suficientes componentes para explicar una proporción adecuada de la varianza total.

```{r tabla varianza}
varianza_tabla <- data.frame(
  Componente = paste0("PC", 1:length(valores_propios)),
  Valor_Propio = round(valores_propios, 4),
  Porcentaje_Varianza = round(valores_propios / sum(valores_propios) * 100, 2),
  Varianza_Acumulada = round(cumsum(valores_propios / sum(valores_propios) * 100), 2)
)
varianza_tabla
```

Con los primeros **3 componentes** (regla de Kaiser) se explica aproximadamente el **63.1%** de la varianza total.
Si se desea alcanzar al menos el **80%**, es necesario retener **6 componentes** (82.5% acumulado).
Existe un compromiso entre parsimonia (menos componentes, más fáciles de interpretar) y cobertura de varianza.
Para este análisis, se consideran los **3 primeros componentes** como los más relevantes por su interpretabilidad y por superar el umbral de Kaiser, aunque se reconoce que no capturan la totalidad de la variabilidad del dataset.

#### Prueba de Paralelismo (Horn's Parallel Analysis)

##### ¿Cómo funciona la Prueba de Paralelismo de Horn?

Se calculan los valores propios del PCA basado en los datos reales.
Se generan múltiples conjuntos de datos aleatorios con el mismo tamaño que los datos originales (mismo número de variables y observaciones).
Se realiza un PCA sobre los datos aleatorios y se extraen los valores propios esperados de cada componente.
Se comparan los valores propios reales con los esperados: Si un componente tiene un valor propio mayor que el de los datos simulados, significa que explica más varianza de la que se esperaría por azar, por lo que se retiene.
Si el valor propio es menor o igual al de los datos aleatorios, el componente no se retiene porque su explicación de varianza es insignificante.

En los resultados de esta prueba los valores simulados son los de la columna "Adjusted Eigenvalue" y los valores reales son "Unadjusted Eigenvalue".
Se retienen los componentes cuyo valor propio real sea mayor que el simulado.

```{r prueba de Horn}
paran(data_numeric, graph = TRUE)
```

### Carga Factorial Interpretativa

Se basa en la interpretación de los componentes.

En la siguiente gráfica se ilustra la calidad de la representación de las variables en las dos primeras dimensiones.

```{r grafico coseno}
fviz_pca_var(compPrinc, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE
)
```

**Interpretación del Gráfico de PCA:**

Representa la relación entre las variables originales proyectadas en el espacio de los dos primeros componentes principales (Dim1 y Dim2).
Vamos a analizarlo paso a paso.

1.  **Ejes del gráfico.** El Eje X (Dim1) representa el primer componente principal (PC1) y el Eje Y (Dim2) representa el segundo componente principal (PC2). Cada eje indica el porcentaje de varianza total que explica. En conjunto, los dos primeros componentes capturan una proporción de la variabilidad total de los datos.

2.  **Longitud de las Flechas (Vectores).** Cada flecha representa una variable original. La longitud de la flecha indica qué tan bien está representada la variable en el espacio de PC1 y PC2. Flechas largas indican que esas variables están bien representadas en los primeros dos componentes. Flechas cortas indican que la variable no está completamente explicada por PC1 y PC2 y puede necesitar más dimensiones para su interpretación.

3.  **Dirección de las Flechas.** Las variables con vectores apuntando en la misma dirección están correlacionadas positivamente. Las variables con vectores opuestos tienen una correlación negativa. Las variables con vectores perpendiculares (ángulo de 90°) están débilmente correlacionadas o no tienen relación.

4.  **Color de las Flechas (cos2 - Calidad de Representación).** El color indica el cos2, que mide la calidad de la representación de cada variable en el espacio de los componentes. Colores cálidos (rojo/naranja) representan variables bien explicadas por los primeros dos componentes (cos2 alto). Colores fríos (azul/verde) representan variables poco explicadas, lo que sugiere que necesitan más dimensiones para su correcta interpretación.

5.  **Relación con los Componentes Principales.** Se identifica qué variables tienen las cargas más altas en cada dimensión para interpretar conceptualmente qué representa cada componente.

### Biplot

El biplot combina la representación de las observaciones y las variables en el espacio de los componentes principales.

```{r biplot}
fviz_pca_biplot(compPrinc, repel = FALSE, 
                col.var = "#FC4E07",
                col.ind = "#00AFBB",
                alpha.ind = 0.1)
```

### Contribución de las variables a cada componente

Los siguientes gráficos muestran qué variables contribuyen más a cada una de las primeras tres dimensiones.
La línea roja discontinua representa la contribución esperada si todas las variables contribuyeran por igual.

```{r contribucion a las componentes}
fviz_contrib(compPrinc, choice = "var", axes = 1, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 2, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 3, top = 10)
```

### Calidad de representación (cos2) por variable y componente

El siguiente gráfico muestra la calidad de la representación de cada variable en cada componente.
Valores altos de cos2 indican que la variable está bien capturada por ese componente.

```{r cos2 corrplot}
var <- get_pca_var(compPrinc)
corrplot(var$cos2, is.corr = FALSE)
```

### Interpretación de las Componentes

Con base en los gráficos de contribución, las cargas factoriales y la calidad de representación, se interpretan los componentes retenidos.

```{r rotacion}
compPrinc$rotation
```

A partir de la matriz de rotación (loadings), se puede interpretar cada componente principal:

1.  **PC1 - Escala general de la película (38.2% de varianza).** Este componente presenta cargas positivas en prácticamente todas las variables: `actorsAmount` (0.39), `castWomenAmount` (0.36), `voteCount` (0.34), `budget` (0.34), `runtime` (0.33), `revenue` (0.32), `voteAvg` (0.32), `productionCoAmount` (0.28) y `genresAmount` (0.26). Es un componente de **tamaño o magnitud general**: películas con valores altos en PC1 son producciones grandes en todos los sentidos (mayor presupuesto, más ingresos, elencos más numerosos, mayor duración, más votos y mejor calificación). Las variables con menor peso son `popularity` (0.12) y `castMenAmount` (0.001), lo que indica que estas dos variables no se alinean con esta dimensión general. Es el patrón típico del primer componente en PCA, que captura la "escala" o "importancia" global del fenómeno.

2.  **PC2 - Producción internacional/artística vs. éxito comercial (13.9% de varianza).** Este componente contrasta dos perfiles de películas a través de cargas de signo opuesto. En el lado positivo: `productionCountriesAmount` (0.46), `castMenAmount` (0.39), `voteAvg` (0.30), `runtime` (0.25) — variables que describen producciones internacionales, con mayor duración y mejor evaluadas cualitativamente. En el lado negativo: `revenue` (-0.40), `budget` (-0.33), `voteCount` (-0.32) — variables que representan el éxito comercial medido en dinero y volumen de votos. Este componente diferencia entre **películas artísticas o de cine independiente/internacional** (rodadas en múltiples países, bien evaluadas pero con menor presupuesto) y **blockbusters comerciales** (alto presupuesto, altos ingresos, muchos votos pero no necesariamente mejor calificación).

3.  **PC3 - Estructura multinacional de producción (11.0% de varianza).** Dominado por cargas negativas fuertes en `castMenAmount` (-0.61) y `productionCountriesAmount` (-0.49), y una carga negativa moderada en `revenue` (-0.30). En el lado positivo, las cargas son más modestas: `productionCoAmount` (0.24), `genresAmount` (0.21). Este componente captura la dimensión de **producción multinacional con elencos masculinos grandes** en contraposición con **producciones con más compañías y diversidad de géneros**. La fuerte influencia de `castMenAmount` debe interpretarse con cautela dado los valores extremos observados en esta variable (media desproporcionada respecto a la mediana).

## Conclusiones

```{r resumen final}
varianza <- summary(compPrinc)
varianza
```

### Resumen de hallazgos

1.  **Viabilidad del PCA:** Las pruebas previas confirmaron la conveniencia de aplicar PCA. El determinante de la matriz de correlación cercano a 0 (`r round(det(rcor), 6)`) indica multicolinealidad. El índice KMO de `r round(resultado_kmo$MSA, 2)` (meritorio) y el rechazo contundente de la prueba de Bartlett (p-value = 0) respaldan la adecuación de los datos para el análisis factorial.

2.  **Dimensionalidad reducida:** Según la regla de Kaiser, se retienen **3 componentes principales** que explican el **63.1%** de la varianza total. Si se requiriera mayor cobertura (80%), serían necesarios 6 componentes. Las `r length(numeric_vars)` variables originales se resumen en 3 ejes decorrelacionados, facilitando el análisis.

3.  **Interpretabilidad de los componentes:**
    -   **PC1 (38.2%)** — **Escala general de la película**: captura la magnitud global de una producción (presupuesto, ingresos, elenco, duración, votos, calificación). Diferencia entre grandes producciones y películas pequeñas.
    -   **PC2 (13.9%)** — **Producción artística/internacional vs. comercial**: contrasta películas rodadas en múltiples países con buenas calificaciones pero menor presupuesto (perfil de cine independiente/artístico) contra blockbusters comerciales de alto presupuesto y altos ingresos.
    -   **PC3 (11.0%)** — **Estructura multinacional de producción**: captura la relación entre la cantidad de países de producción, la composición masculina del elenco y la diversidad de géneros/compañías.

4.  **Observaciones sobre la calidad de los datos:** La variable `castMenAmount` presenta valores extremos (media desproporcionada respecto a la mediana, con un máximo de 922,017) que afectan su comportamiento en el PCA. Esto se refleja en su MSA bajo (0.50) y su carga casi nula en PC1. Para futuros análisis, se recomienda investigar y tratar estos outliers antes de aplicar PCA.

5.  **Utilidad para modelos predictivos:** Al utilizar los componentes principales en lugar de las `r length(numeric_vars)` variables originales, se reduce la dimensionalidad, se eliminan problemas de multicolinealidad y se facilita la construcción de modelos de predicción futuros con variables decorrelacionadas.

6.  **Recomendaciones para CineVision Studios:**
    -   **Perfilamiento de películas:** Los tres componentes permiten ubicar cada película en un espacio tridimensional interpretable (escala general, perfil comercial vs. artístico, estructura de producción).
    -   **Segmentación estratégica:** CineVision Studios puede segmentar su catálogo según estos ejes para identificar nichos de mercado no explotados, por ejemplo, películas con alto potencial artístico (PC2 alto) pero baja visibilidad comercial.
    -   **Modelos predictivos:** Utilizar los scores de los componentes como variables de entrada para modelos de predicción de ingresos o popularidad, aprovechando que están decorrelacionados.
    -   **Limpieza de datos:** Antes de aplicar modelos avanzados, se recomienda revisar la variable `castMenAmount` y `productionCountriesAmount` para corregir posibles errores de registro.


# 4.1
## Justificación de la Selección: UMAP
Para esta última fase de la consultoría, se evaluaron las cuatro opciones propuestas (SVD, t-SNE, UMAP, ICA). Se descartó SVD por ser el motor matemático subyacente del PCA (ya realizado, resultaría redundante) e ICA porque las variables cinematográficas (presupuesto, ingresos, popularidad) están altamente entrelazadas y no provienen de "fuentes independientes" puras.

Entre t-SNE y UMAP, se seleccionó UMAP. A diferencia del PCA, que es lineal y puede superponer grupos en su proyección 2D, UMAP es un algoritmo de reducción de dimensionalidad no lineal excelente para separar visualmente "islas" de datos complejos. Se prefirió por encima de t-SNE debido a su superior eficiencia computacional y menor consumo de memoria RAM, lo cual es vital dada la alta carga de procesamiento que exige este volumen de datos. Esta técnica permitirá a CineVision Studios tener un mapa visual topológico claro para validar si los 4 perfiles comerciales descubiertos en el clustering realmente forman agrupaciones separadas y naturales.

```{r umap}
library(umap)
library(ggplot2)
library(dplyr)

cat("Ejecutando algoritmo UMAP...\n")

# Configuración de UMAP
umap_config <- umap.defaults
umap_config$random_state <- 666 

umap_res <- umap(movies_sample_scaled, config = umap_config)

# dataframe combinando las coordenadas UMAP y los Clústeres de K-Medias
umap_data <- data.frame(
  UMAP1 = umap_res$layout[, 1],
  UMAP2 = umap_res$layout[, 2],
  Cluster_KMeans = movies_sample_cluster$Cluster_KMeans
)

# grafico de dispersión no lineal
grafica_umap <- ggplot(umap_data, aes(x = UMAP1, y = UMAP2, color = Cluster_KMeans)) +
  geom_point(alpha = 0.7, size = 2.5) +
  theme_minimal() +
  labs(title = "Proyección UMAP: Visualización Topológica de Películas",
       subtitle = "Mapeo no lineal coloreado según los 4 perfiles comerciales (K-Medias)",
       x = "UMAP Dimensión 1",
       y = "UMAP Dimensión 2",
       color = "Clúster") +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "right")

print(grafica_umap)
```
# 4.2
El mapa visual generado por el algoritmo UMAP confirma claramente que los cuatro grupos de películas descubiertos antes están bien separados en la realidad. Se observa un núcleo principal que agrupa al cine comercial exitoso, el cual está muy alejado de las producciones amateur o cortometrajes que aparecen dispersos por su gran variedad de formatos. Por otro lado, las películas épicas y el cine independiente de nicho forman sus propias islas totalmente aisladas del resto. Para CineVision Studios, este gráfico funciona como un radar de riesgo muy útil para predecir de forma visual a qué modelo de negocio pertenecerá cualquier nuevo proyecto.

# 5.1
## Hallazgos, Conclusiones y Sugerencias

### Hallazgos del Agrupamiento (Clustering)

El mercado cinematográfico no es uniforme, sino que se divide en **cuatro perfiles** claramente diferenciados:

1. **Cine Comercial Exitoso:** Núcleo principal de la industria con duración estándar (~100 min), presupuestos y recaudaciones altas, y buena popularidad. Dominado por el idioma inglés y géneros masivos (Drama, Action, Comedy).
2. **Producciones Épicas Aclamadas:** Películas de larga duración con elencos numerosos que logran las calificaciones más altas del público. Representan una fracción pequeña del mercado pero concentran el prestigio.
3. **Cine Independiente:** Producciones de duración tradicional pero con presupuesto mínimo. Generan poco dinero pero atraen a nichos específicos y mercados no angloparlantes.
4. **Cortometrajes/Amateur:** Proyectos de muy corta duración con presupuestos, elencos y ganancias prácticamente nulos. Constituyen un volumen grande del dataset pero sin impacto comercial.

La calidad del agrupamiento fue validada mediante el coeficiente de silueta para ambos algoritmos (K-Medias y jerárquico), seleccionando K-Medias por su mejor desempeño.
Las medidas de tendencia central (media y mediana) y las tablas de frecuencia de variables categóricas (idioma y género por cluster) confirmaron la diferenciación entre los perfiles.

### Conclusiones del Análisis de Componentes Principales (PCA)

Se confirmó la viabilidad del PCA mediante tres pruebas: el determinante de la matriz de correlación cercano a 0 (multicolinealidad), el índice KMO de 0.82 (meritorio) y el rechazo de la prueba de Bartlett (p = 0).
Las `r length(numeric_vars)` variables numéricas se resumieron en **3 componentes principales** (regla de Kaiser) que explican el **63.1%** de la varianza total:

* **PC1 (38.2%)** — Escala general: diferencia entre grandes producciones y películas pequeñas en todas las dimensiones (presupuesto, ingresos, elenco, duración, votos).
* **PC2 (13.9%)** — Artístico/internacional vs. comercial: contrasta películas de cine independiente/internacional (bien calificadas, muchos países de producción, menor presupuesto) contra blockbusters comerciales (alto presupuesto, altos ingresos).
* **PC3 (11.0%)** — Estructura multinacional de producción: captura la relación entre países de producción, composición del elenco y diversidad de géneros.

Se identificó que `castMenAmount` presenta valores extremos que afectan su comportamiento en el PCA (MSA = 0.50, carga casi nula en PC1), recomendando su revisión antes de futuros análisis.

### Reglas de Asociación más Interesantes

Se probaron tres combinaciones de soporte y confianza (0.05/0.6, 0.03/0.7, 0.01/0.8) y se identificó que el equilibrio óptimo es soporte entre 0.02-0.03 y confianza de 0.7.
La eliminación del idioma inglés como variable dominante fue clave para descubrir patrones ocultos.

Las reglas más interesantes (mayor lift) revelaron:

* Asociaciones fuertes entre **presupuestos altos, ingresos altos y cantidad alta de votos**: este patrón confirma que la inversión en producción se traduce proporcionalmente en recaudación y visibilidad.
* Relaciones entre **popularidad baja y rangos bajos de presupuesto/revenue**: películas con poca inversión tienden a permanecer invisibles para el público.
* Al eliminar el inglés, surgieron asociaciones específicas entre idiomas no angloparlantes y rangos de calificación/presupuesto, revelando dinámicas de mercados cinematográficos regionales.

### Otros Algoritmos: UMAP

Se seleccionó UMAP por su capacidad de reducción de dimensionalidad no lineal, superior a t-SNE en eficiencia computacional.
El mapa topológico generado validó visualmente los 4 clusters: las películas de nicho y las súper-producciones forman "islas" completamente separadas del núcleo comercial, confirmando que operan bajo modelos de negocio estadísticamente distintos.
A diferencia del PCA (que es lineal y puede superponer grupos), UMAP preserva la estructura local y global de los datos, revelando la separación real entre los segmentos.

## Sugerencias para CineVision Studios

Con base en todos los descubrimientos realizados, se proponen las siguientes acciones estratégicas:

1. **Apostar por el cine comercial estándar:** Dirigir la mayor parte de la inversión a películas de formato tradicional (~100 minutos, presupuesto moderado-alto), ya que el clustering demostró que son la opción más segura, popular y rentable. Las reglas de asociación confirman que la inversión en este rango se traduce proporcionalmente en ingresos y visibilidad.

2. **Invertir selectivamente en prestigio:** Producir solo uno o dos proyectos épicos al año (gran elenco, larga duración). El PCA mostró que estas producciones se ubican en el extremo positivo de PC1 (escala general) y PC2 (perfil artístico), combinando magnitud y calidad que generan reconocimiento.

3. **Usar el mapa UMAP como filtro de riesgo:** Antes de aprobar y financiar un nuevo proyecto, ubicarlo en el mapa topológico para predecir rápidamente a qué perfil comercial pertenecerá. Si cae en la zona de cortometrajes/amateur, reconsiderar la inversión.

4. **Cambiar la distribución del cine independiente:** Las películas de bajo presupuesto y de nicho no deben gastar en publicidad masiva para cines. Su estrategia debe orientarse a festivales especializados y plataformas de streaming, donde las reglas de asociación muestran que tienen mejor recepción.


5. **Explorar mercados internacionales:** El PC2 del PCA y las reglas de asociación filtradas (sin inglés) revelaron dinámicas específicas en mercados no angloparlantes. CineVision Studios podría diversificar su portafolio produciendo o distribuyendo contenido en idiomas con potencial comercial no explotado.

6. **Depurar la base de datos:** Corregir los valores extremos detectados en `castMenAmount` y `productionCountriesAmount` para mejorar la calidad de futuros análisis predictivos.

## Conclusión General

Este proyecto demuestra que la integración de clustering, reducción de dimensionalidad y reglas de asociación permite transformar un dataset complejo en conocimiento estratégico accionable para la industria cinematográfica.

El análisis confirmó que el mercado no es homogéneo, sino que se estructura en cuatro perfiles claramente diferenciados, cada uno con dinámicas propias de presupuesto, duración, popularidad y rentabilidad. La coherencia de estos grupos fue validada mediante el coeficiente de silueta, seleccionando K-Means como el algoritmo con mejor desempeño.

El PCA permitió resumir eficientemente la información original en tres componentes principales que explican más del 60% de la variabilidad, identificando como eje dominante la escala global de producción (presupuesto, ingresos y volumen de votos). Por su parte, UMAP confirmó visualmente que los segmentos identificados operan bajo modelos de negocio estadísticamente distintos.

* En el análisis de reglas de asociación se evidenció que:

* La discretización fue esencial para aplicar Apriori correctamente.

* El soporte controla la frecuencia mínima de aparición de patrones.

* La confianza mide el poder predictivo de las reglas.

* El lift permitió identificar asociaciones no triviales.

* La eliminación de variables dominantes (como el idioma inglés) permitió descubrir patrones ocultos en mercados no angloparlantes.

* Se confirmó una relación estructural fuerte entre altos presupuestos, altos ingresos y mayor visibilidad, mientras que las producciones de bajo presupuesto tienden a concentrarse en nichos con impacto comercial limitado.

* Finalmente, se recomienda depurar variables con valores extremos (como castMenAmount y productionCountriesAmount) para mejorar la calidad de futuros modelos predictivos.

En términos estratégicos, el verdadero valor de este análisis radica en su capacidad para clasificar proyectos futuros antes de invertir en ellos, permitiendo reducir riesgo, optimizar el portafolio y definir con claridad en qué modelo de negocio desea competir el estudio: volumen comercial, prestigio, nicho especializado o producción experimental.





