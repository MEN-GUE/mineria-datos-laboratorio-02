---
title: "lab02"
output:
  html_document: default
  pdf_document: default
date: "2026-02-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read csv
```{r load csv}
data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)
```

# 1.1
```{r summary}

library(dplyr)
library(tidyr)

# Excluímos id, textos, y variables de muy baja varianza (video)
movies_cluster <- data %>%
  select(budget, revenue, runtime, popularity, voteAvg, voteCount, 
         genresAmount, productionCoAmount, productionCountriesAmount, 
         actorsAmount, castWomenAmount, castMenAmount, releaseYear)

movies_cluster <- movies_cluster %>% 
  drop_na()

# Escalamiento 
movies_scaled <- as.data.frame(scale(movies_cluster))

# REsultado
summary(movies_scaled)
head(movies_scaled)
```

# 1.2
```{r hopkins-vat}
library(factoextra)
library(dplyr)

movies_sample <- movies_scaled %>% sample_n(1500)
tendencia <- get_clust_tendency(movies_sample, n = 50, graph = TRUE)

# --- RESULTADOS

# Hopkins
cat("Estadístico de Hopkins:", tendencia$hopkins_stat, "\n")

# VAT
print(tendencia$plot)
```
Podemos observar un valor estadístico de hopkins de 0.942, muy cercano 1, lo que indica cierta practicidad en realizar agrupaciones de datos, la prueba VAT también arroja cómo gráficamente los datos parecen mostrar ciertas tenedencias, detectamos al menos 4 grupos posibles separados, por lo que se puede proceder al clustering.

# 1.3
```{r metodos de evaluacion de agrupamiento futuro}
library(factoextra)
library(NbClust)
library(dplyr)
library(ggplot2)

set.seed(666)
movies_sample_opt <- movies_scaled %>% sample_n(1500)

# Metodo del codo
cat("Generando gráfica del Método del Codo...\n")
grafica_codo <- fviz_nbclust(movies_sample_opt, kmeans, method = "wss") +
  labs(title = "Método del Codo para determinar K óptimo",
       x = "Número de clústeres (k)", 
       y = "Suma de Cuadrados Intra-clúster (WSS)")

print(grafica_codo)

# Metodo nbclust
# Usamos invisible() y capture.output() para evitar que NbClust imprima demasiado texto en el PDF
cat("Ejecutando NbClust para evaluar 30 índices...\n")
invisible(capture.output(
  resultados_nbclust <- NbClust(data = movies_sample_opt, 
                                distance = "euclidean", 
                                min.nc = 2, max.nc = 10, 
                                method = "kmeans", 
                                index = "all")
))


votos <- as.data.frame(table(resultados_nbclust$Best.nc[1, ]))
colnames(votos) <- c("Clusters", "Frecuencia")

# Grafica
grafica_votos <- ggplot(votos, aes(x = Clusters, y = Frecuencia)) +
  geom_bar(stat = "identity", fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Número Óptimo de Clústeres - Votación Mayoritaria (NbClust)",
       x = "Número de clústeres (k) propuesto",
       y = "Frecuencia (Cantidad de índices)") +
  theme(plot.title = element_text(face = "bold"))

print(grafica_votos)
```
Las pruebas realizada con la ayuda de la libreria NbClust dan un por la regla de la mayoría una recomendación de agrupamiento mediante 4 clusters. Esto es apoyado por el método del codo, dónde gráficamente observamos un punto de inflección muy claro entre 3 y 4, debido a las pruebas de Nbcluts decidimos irnos por un total de 4 grupos.

# 1.4
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(factoextra)

set.seed(666)
indices_muestra <- sample(1:nrow(movies_cluster), 2000)

# Filtramos
movies_sample_cluster <- movies_cluster[indices_muestra, ]
movies_sample_scaled <- as.data.frame(scale(movies_sample_cluster))

# k-medias
km_res <- kmeans(movies_sample_scaled, centers = 4, nstart = 25)

movies_sample_cluster$Cluster_KMeans <- as.factor(km_res$cluster)

# jerarquico
cat("Calculando matriz de distancias para 2000 registros...\n")
distancias <- dist(movies_sample_scaled, method = "euclidean")

cat("Generando árbol jerárquico...\n")
hc_res <- hclust(distancias, method = "ward.D2")

grupos_hc <- cutree(hc_res, k = 4)
movies_sample_cluster$Cluster_HC <- as.factor(grupos_hc)

# comparacion
cat("\nMatriz de Confusión (K-Medias vs Jerárquico):\n")
tabla_comparacion <- table(K_Medias = movies_sample_cluster$Cluster_KMeans, 
                           Jerarquico = movies_sample_cluster$Cluster_HC)
print(tabla_comparacion)

# pca
grafico_pca <- fviz_cluster(km_res, data = movies_sample_scaled, 
                            geom = "point", 
                            ellipse.type = "convex", 
                            ggtheme = theme_minimal(),
                            main = "Agrupamiento K-Medias (Muestra 2000 obs)")
print(grafico_pca)

# grafico radar (mi favorito)
centroides_escalados <- movies_sample_scaled %>%
  mutate(Cluster = as.factor(km_res$cluster)) %>%
  group_by(Cluster) %>%
  summarise_all(mean)

centroides_largo <- centroides_escalados %>%
  pivot_longer(cols = -Cluster, names_to = "Variable", values_to = "Media_Escalada")

grafico_radar <- ggplot(centroides_largo, aes(x = Variable, y = Media_Escalada, color = Cluster, group = Cluster)) +
  geom_polygon(fill = NA, linewidth = 1) + 
  geom_point(size = 2) +
  geom_line(linewidth = 0.5, linetype = "dashed") +
  coord_polar() + 
  theme_minimal() +
  labs(title = "Perfil de los 4 Clusters (K-Medias en Muestra)",
       subtitle = "Valores estandarizados: 0 es el promedio de la variable",
       y = "Media Estandarizada") +
  theme(axis.text.x = element_text(angle = 0, size = 10, face = "bold"),
        legend.position = "right")

print(grafico_radar)
```
Podemos observar que ambos métodos de agrupamiento, tanto k-medias como jerárquico, muestran una tendencia similar en la asignación de registros a los clusters, aunque no son idénticos. La matriz de confusión revela que hay cierta superposición entre los grupos formados por ambos métodos, lo que sugiere que aunque no coinciden perfectamente, sí capturan patrones similares en los datos. El gráfico PCA muestra una clara separación entre los clusters formados por k-medias, mientras que el gráfico de radar  para este caso no es lo más eficiente para representar visualmente lo que están experimentando los datos.

# 1.5
```{r}
library(cluster)
library(factoextra)

cat("Calculando el coeficiente de silueta para K-Medias...\n")

# silueta
sil_kmeans <- silhouette(km_res$cluster, dist(movies_sample_scaled))
summary(sil_kmeans)
grafica_silueta <- fviz_silhouette(sil_kmeans, 
                                   palette = "jco", 
                                   ggtheme = theme_minimal(),
                                   main = "Gráfico de Silueta - Calidad de K-Medias (K=4)")

print(grafica_silueta)
```
El análisis de silueta nos permitió evaluar de manera visual qué tan bien integradas están las películas dentro de sus respectivos grupos. El resultado mostró un promedio general positivo, lo que confirma que la mayoría de las películas comparten características fuertes con su propio segmento y se diferencian adecuadamente de los demás. Aunque se observaron algunas películas con valores negativos, esto es completamente normal en esta industria, ya que representan producciones "fronterizas" que mezclan presupuestos o atributos de distintos grupos. En conclusión, esta métrica nos asegura que la segmentación en cuatro grupos es lo suficientemente sólida y confiable para basar en ella futuras decisiones comerciales.

# 1.6
```{r}
library(dplyr)
library(knitr)

# Calculamos el promedio de las variables originales (sin estandarizar) para cada cluster
# Esto nos permite interpretar los grupos con valores reales (dólares, minutos, cantidad de actores, etc.)
perfil_clusters <- movies_sample_cluster %>%
  group_by(Cluster_KMeans) %>%
  summarise(
    Cantidad_Peliculas = n(),
    Presupuesto_Promedio = mean(budget, na.rm = TRUE),
    Ingresos_Promedio = mean(revenue, na.rm = TRUE),
    Duracion_Promedio = mean(runtime, na.rm = TRUE),
    Popularidad_Promedio = mean(popularity, na.rm = TRUE),
    Calificacion_Promedio = mean(voteAvg, na.rm = TRUE),
    Elenco_Promedio = mean(actorsAmount, na.rm = TRUE)
  )

# Mostramos la tabla formateada
kable(perfil_clusters, format = "markdown", digits = 2, 
      caption = "Perfilamiento de los 4 Clusters (Valores Promedio Originales)")
```
nterpretación comercial de los grupos:

* Grupo 4 (Cine Comercial Exitoso): Es el estándar rentable de la industria; películas populares, de duración normal y buenos ingresos.
* Grupo 2 (Épicas Aclamadas): Producciones muy largas y con elencos gigantes, que logran las mejores calificaciones del público.
* Grupo 1 (Cortometrajes o Amateur): Proyectos de muy corta duración, con presupuestos, elencos y ganancias prácticamente nulos.
* Grupo 3 (Cine Independiente): Películas de duración tradicional pero con presupuesto mínimo; generan poco dinero pero atraen a nichos específicos.

# Parte 2
# 1. Introducción

En esta sección se obtienen **reglas de asociación** utilizando el algoritmo **Apriori** sobre el conjunto de datos `movies_2026.csv`.

Se realiza:

* Discretización de variables numéricas.
* Generación de reglas con diferentes niveles de soporte y confianza.
* Evaluación del lift.
* Eliminación de variables muy frecuentes para obtener mejores insights.

---

# 2. Carga de Datos
```{r}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(arules)
library(arulesViz)
```

```{r}
movies <- read.csv("movies_2026.csv", encoding = "latin1")
str(movies)
summary(movies)
```

---

# 3. Selección de Variables

Seleccionamos las variables relevantes para minería de reglas:

* genres
* originalLanguage
* budget
* revenue
* runtime
* popularity
* voteAvg
* voteCount

```{r}
movies2 <- movies %>%
  select(genres, originalLanguage, budget, revenue, runtime,
         popularity, voteAvg, voteCount) %>%
  drop_na(genres)
```

---

# 4. Discretización de Variables Numéricas

El algoritmo Apriori requiere variables categóricas. Se discretizan las variables numéricas usando cuantiles (3 categorías).

```{r}
movies2 <- movies2 %>%
  mutate(
    budget_cat = discretize(budget, method = "frequency", categories = 3),
    revenue_cat = discretize(revenue, method = "frequency", categories = 3),
    runtime_cat = discretize(runtime, method = "frequency", categories = 3),
    popularity_cat = discretize(popularity, method = "frequency", categories = 3),
    voteAvg_cat = discretize(voteAvg, method = "frequency", categories = 3),
    voteCount_cat = discretize(voteCount, method = "frequency", categories = 3)
  )

movies2 <- movies2 %>%
  select(genres, originalLanguage,
         budget_cat, revenue_cat, runtime_cat,
         popularity_cat, voteAvg_cat, voteCount_cat)
```

---

# 5. Conversión a Formato Transaccional

```{r}
movies_trans <- as(movies2, "transactions")
summary(movies_trans)
```

---

# 6. Generación de Reglas

## 6.1 Soporte = 0.05 | Confianza = 0.6

```{r}
rules1 <- apriori(movies_trans,
                  parameter = list(supp = 0.05,
                                   conf = 0.6,
                                   minlen = 2))

inspect(sort(rules1, by = "lift")[1:10])
```

### Discusión

Con soporte alto se generan pocas reglas y suelen estar dominadas por categorías frecuentes.

---

## 6.2 Soporte = 0.03 | Confianza = 0.7

```{r}
rules2 <- apriori(movies_trans,
                  parameter = list(supp = 0.03,
                                   conf = 0.7,
                                   minlen = 2))

inspect(sort(rules2, by = "lift")[1:10])
```

### Discusión

Se obtiene un mejor equilibrio entre cantidad y calidad de reglas.

---

## 6.3 Soporte = 0.01 | Confianza = 0.8

```{r}
rules3 <- apriori(movies_trans,
                  parameter = list(supp = 0.01,
                                   conf = 0.8,
                                   minlen = 2))

inspect(sort(rules3, by = "lift")[1:10])
```

### Discusión

Se generan muchas reglas. Aunque la confianza es alta, algunas pueden tener bajo soporte práctico.

---

# 7. Identificación de Ítems Muy Frecuentes

```{r}
itemFrequencyPlot(movies_trans, topN = 20, type = "absolute")
```

Es probable que el idioma inglés ("en") y categorías de bajo presupuesto o bajo revenue dominen las reglas.

---

# 8. Eliminación de Variable Muy Frecuente

Se elimina el idioma inglés para evaluar si emergen reglas más interesantes.

```{r}
movies3 <- movies2 %>%
  filter(originalLanguage != "en")

movies_trans2 <- as(movies3, "transactions")

rules_filtered <- apriori(movies_trans2,
                          parameter = list(supp = 0.02,
                                           conf = 0.7,
                                           minlen = 2))

inspect(sort(rules_filtered, by = "lift")[1:10])
```

### Discusión

Al eliminar una variable dominante:

* Se reduce el sesgo en las reglas.
* Aparecen asociaciones más específicas.
* Se obtienen mejores insights entre género, presupuesto, popularidad y votaciones.

---

# 9. Conclusiones

* La discretización es esencial para aplicar Apriori.
* El soporte controla la frecuencia mínima.
* La confianza mide la fuerza predictiva.
* El lift permite identificar asociaciones no triviales.
* Eliminar variables muy frecuentes mejora la calidad de los resultados.
* Un equilibrio adecuado (supp ≈ 0.02–0.03 y conf ≈ 0.7) genera reglas interpretables.

---

# 10. Visualización de Reglas

```{r}
plot(rules_filtered, method = "graph", engine = "htmlwidget")
```

# Parte 3
```{r paquetes y datos}
if(! "psych" %in% installed.packages()) install.packages("psych", depend = TRUE)
if(! "FactoMineR" %in% installed.packages()) install.packages("FactoMineR", depend = TRUE)
if(! "corrplot" %in% installed.packages()) install.packages("corrplot", depend = TRUE)
if(! "fpc" %in% installed.packages()) install.packages("fpc", depend = TRUE)
if(! "factoextra" %in% installed.packages()) install.packages("factoextra", depend = TRUE)
if(! "PCAmixdata" %in% installed.packages()) install.packages("PCAmixdata", depend = TRUE)
if(! "paran" %in% installed.packages()) install.packages("paran", depend = TRUE)

library(psych)
library(FactoMineR)
library(fpc)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)

data <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)

numeric_vars <- c("budget", "revenue", "runtime", "popularity",
                  "voteAvg", "voteCount", "genresAmount",
                  "productionCoAmount", "productionCountriesAmount",
                  "actorsAmount", "castWomenAmount", "castMenAmount")

categorical_vars <- c("genres", "originalLanguage", "video", "director",
                      "actors", "productionCompany", "productionCountry", "homePage")

numeric_vars_list <- paste(numeric_vars, collapse = ", ")
categorical_vars_list <- paste(categorical_vars, collapse = ", ")
```

## Descripción de los datos

El análisis se realizó sobre un conjunto de **`r format(nrow(data), big.mark = ",")`** películas obtenidas de la plataforma "The Movie DB".
A continuación, se describen las variables incluidas en el estudio:

------------------------------------------------------------------------

| **Variable** | **Descripción** |
|-----------------------------------|-------------------------------------|
| **id** | Identificador único de la película. |
| **popularity** | Índice de popularidad calculado semanalmente. |
| **budget** | Presupuesto de la película (en USD). |
| **revenue** | Ingresos generados por la película (en USD). |
| **runtime** | Duración de la película en minutos. |
| **voteAvg** | Promedio de votos en la plataforma. |
| **voteCount** | Número de votos recibidos. |
| **genresAmount** | Cantidad de géneros que representa la película. |
| **productionCoAmount** | Cantidad de compañías productoras involucradas. |
| **productionCountriesAmount** | Cantidad de países donde se rodó la película. |
| **actorsAmount** | Cantidad de actores en el elenco. |
| **castWomenAmount** | Cantidad de actrices en el elenco. |
| **castMenAmount** | Cantidad de actores masculinos en el elenco. |
| **releaseYear** | Año de lanzamiento. |

------------------------------------------------------------------------

### Variables numéricas seleccionadas para el PCA

Para el análisis de componentes principales se utilizarán **`r length(numeric_vars)` variables numéricas** que aportan información cuantitativa relevante sobre las películas: `r numeric_vars_list`.

Se excluyen:

-   **id**: Es un identificador único, no aporta información para el análisis.
-   **releaseYear**: Presenta muy poca variabilidad (la mayoría de registros pertenecen a años similares) y no contribuye a diferenciar entre películas.

```{r seleccion de variables numericas}
data_numeric <- data[, numeric_vars]

data_numeric <- na.omit(data_numeric)

str(data_numeric)
summary(data_numeric)
```

## 3.1 Transformación de variables categóricas para incluirlas en el PCA

Antes de proceder con el PCA, es necesario evaluar si vale la pena transformar las variables categóricas del dataset para incluirlas en el análisis.

### Variables categóricas del dataset

El dataset contiene **`r length(categorical_vars)` variables categóricas**: `r categorical_vars_list`.

-   **genres**: Géneros de la película, separados por `|`. Ejemplo: "Drama|Crime". Cada película puede tener múltiples géneros.
-   **originalLanguage**: Idioma original de la película (e.g., "en", "fa", "es").
-   **video**: Indica si tiene videos promocionales (TRUE/FALSE).
-   **director**: Director de la película.
-   **actors**: Elenco de la película, separado por `|`.
-   **productionCompany**: Compañías productoras.
-   **productionCountry**: Países de producción.
-   **homePage**: Página web de la película.

### Análisis de viabilidad

```{r cardinalidad categoricas}
cardinalidad <- sapply(categorical_vars, function(v) length(unique(data[[v]])))
data.frame(Variable = names(cardinalidad), Valores_Unicos = cardinalidad, row.names = NULL)

cat("\nDistribución de 'video':\n")
table(data$video)
```

### Opciones de transformación

1.  **One-Hot Encoding**: Consiste en crear una columna binaria por cada categoría. Sin embargo, variables como `director` y `actors` tienen miles de valores únicos, lo que generaría una matriz extremadamente dispersa y de altísima dimensionalidad, lo cual contradice el objetivo del PCA (reducir dimensiones).

2.  **Separación de géneros**: La variable `genres` podría separarse por `|` y codificarse como columnas binarias por género individual. Aunque es viable, esto añade múltiples columnas con baja frecuencia para géneros poco comunes.

3.  **PCAmixdata**: El paquete `PCAmixdata` permite realizar un PCA sobre datos mixtos (numéricos y categóricos). Sin embargo, requiere que las variables categóricas tengan una cantidad razonable de niveles. Con la cardinalidad observada en `director`, `actors` y `productionCompany`, el análisis sería computacionalmente costoso y los resultados difíciles de interpretar.

4.  **Variable `video`**: Aunque es trivialmente codificable como 0/1, tiene varianza cercana a cero porque casi todas las observaciones tienen el mismo valor (FALSE), por lo que no aportaría al PCA.

### Conclusión

**No vale la pena incluir las variables categóricas en el PCA.** Las razones principales son:

-   La altísima cardinalidad de variables como `director`, `actors` y `productionCompany` generaría una explosión dimensional.
-   Las variables con baja cardinalidad (`video`) tienen varianza casi nula.
-   El PCA está diseñado para capturar la variabilidad en variables continuas; las transformaciones binarias de categóricas producen matrices dispersas que dificultan la interpretación de los componentes.

Se procederá con las **`r length(numeric_vars)` variables numéricas** seleccionadas previamente.

## 3.2 ¿Es conveniente hacer un Análisis de Componentes Principales?

### 3.2.1 Determinante de la Matriz de Correlación

Lo primero que vamos a hacer es calcular el determinante de la matriz de correlación.
Si este es cercano a 0 significa que hay multicolinealidad, es decir, las variables están relacionadas entre sí.

```{r matriz de correlacion determinante}
rcor <- cor(data_numeric, use = "pairwise.complete.obs")
```

El determinante es: `r round(det(rcor), 6)`.

El valor obtenido (`r round(det(rcor), 6)`) es muy cercano a 0, lo que confirma la presencia de multicolinealidad entre las variables.
Esto significa que las variables numéricas comparten información redundante, lo cual es una condición favorable para aplicar PCA: el análisis buscará resumir esa redundancia en pocas componentes que capturen la mayor parte de la variabilidad.

### 3.2.2 KMO (Kaiser-Meyer-Olkin)

Se debe analizar si se puede usar el análisis factorial para formar las combinaciones lineales de las variables.
El índice KMO mide la adecuación muestral según la siguiente escala:

-   \< 0.5: Inaceptable
-   0.5 - 0.6: Miserable
-   0.6 - 0.7: Mediocre
-   0.7 - 0.8: Aceptable
-   0.8 - 0.9: Meritorio
-   \> 0.9: Excelente

```{r KMO}
resultado_kmo <- KMO(as.matrix(data_numeric))
resultado_kmo
```

El índice general obtenido (Overall MSA = `r round(resultado_kmo$MSA, 2)`) se clasifica como **meritorio**, lo que indica que los datos son adecuados para un análisis factorial.
Esto respalda fuertemente la aplicación de PCA.

Al examinar los valores MSA individuales por variable, se observa que la mayoría superan 0.8, lo que refuerza su inclusión.
Las variables `castMenAmount` (MSA = `r round(resultado_kmo$MSAi["castMenAmount"], 2)`) y `productionCountriesAmount` (MSA = `r round(resultado_kmo$MSAi["productionCountriesAmount"], 2)`) presentan los valores más bajos, en el umbral de lo aceptable, lo que sugiere que estas variables comparten menos estructura factorial con el resto.
No obstante, al estar por encima de 0.5, se mantienen en el análisis.

### 3.2.3 Test de Esfericidad de Bartlett

H0: La matriz de correlaciones es igual a la matriz identidad.\
Se busca rechazar la hipótesis nula de que la matriz de correlaciones es igual a la matriz identidad y por ende, que existe suficiente multicolinealidad entre las variables.
En una matriz de identidad la diagonal es 1, y los valores fuera de la diagonal son 0.
Esto implica que no hay más colinealidad entre las variables que la que hay entre cada variable consigo misma.

```{r Bartlett}
resultado_bartlett <- cortest.bartlett(data_numeric)
resultado_bartlett
```

El estadístico chi-cuadrado obtenido es `r format(round(resultado_bartlett$chisq, 1), big.mark = ",")` con `r resultado_bartlett$df` grados de libertad, y un valor p de `r resultado_bartlett$p.value`.
Al ser el valor p prácticamente 0 (mucho menor a 0.05), rechazamos H0 y concluimos que la matriz de correlaciones es significativamente diferente a la matriz identidad.
Esto confirma que existe suficiente multicolinealidad entre las variables y que el análisis factorial (y por tanto el PCA) es apropiado para estos datos.

En conjunto, tanto el determinante cercano a 0, el KMO meritorio (0.82) y el rechazo contundente de la prueba de Bartlett **confirman que es conveniente aplicar un Análisis de Componentes Principales** a este dataset.

### 3.2.4 Matriz de Correlación

A continuación se visualiza la matriz de correlación para identificar las relaciones más fuertes entre variables.

```{r corrplot}
matriz <- cor(data_numeric, use = "pairwise.complete.obs")
corrplot(matriz, method = "color", type = "upper", 
         tl.cex = 0.7, tl.col = "black",
         addCoef.col = "black", number.cex = 0.5)
```

En la matriz de correlación se pueden identificar varios patrones relevantes:

-   **`budget` y `revenue`** presentan una correlación positiva notable, lo cual es esperable: películas con mayor presupuesto tienden a generar mayores ingresos.
-   **`budget`, `revenue` y `voteCount`** forman un bloque correlacionado que refleja la dimensión comercial de las películas. `voteCount` se asocia con mayor visibilidad y presencia en la plataforma.
-   **`actorsAmount` y `castWomenAmount`** muestran correlación positiva, lo cual es lógico porque la cantidad de actrices es un subconjunto del elenco total. Sin embargo, `castMenAmount` presenta un comportamiento anómalo con correlaciones bajas respecto al resto de variables del elenco, posiblemente debido a valores extremos en esta variable (su media es desproporcionadamente alta respecto a la mediana, sugiriendo la presencia de outliers severos).
-   **`runtime`** se correlaciona moderadamente con `voteAvg`, `genresAmount` y `productionCoAmount`, lo que sugiere que las películas más largas tienden a ser producciones más complejas y mejor evaluadas.
-   **`popularity`** muestra correlaciones débiles con la mayoría de variables, lo que indica que es una métrica más independiente que depende de factores temporales y externos no capturados por las demás variables.
-   **`productionCountriesAmount`** tiene correlaciones bajas con el bloque financiero, lo que sugiere que la cantidad de países de producción no se relaciona linealmente con el éxito comercial.

## 3.3 Análisis de Componentes Principales

### 3.3.1 Ejecución del PCA

Para hacer el análisis de componentes principales es necesario normalizar los datos.
La función `prcomp` lo hace automáticamente con el parámetro `scale = TRUE`.

```{r PCA prcomp}
compPrinc <- prcomp(data_numeric, scale = TRUE)
compPrinc
```

El resumen del modelo es el siguiente:

```{r resumen PCA}
summary(compPrinc)
```

También ejecutamos el PCA con `FactoMineR::PCA()` para obtener información adicional:

```{r PCA FactoMineR}
compPrincPCA <- PCA(data_numeric, ncp = ncol(data_numeric), scale.unit = TRUE, graph = FALSE)
summary(compPrincPCA)
```

### Selección de Componentes

#### Regla de Kaiser

Los valores propios (eigenvalues) de cada componente son los siguientes:

```{r eigenvalues}
valores_propios <- compPrinc$sdev^2
nombres_pc <- paste0("PC", 1:length(valores_propios))
data.frame(Componente = nombres_pc, Valor_Propio = round(valores_propios, 4))
```

Según la regla de Kaiser, debemos quedarnos con los componentes que tienen valores propios mayores a 1.
Los componentes con valor propio menor a 1 explican menos varianza que una sola variable original estandarizada, por lo que no aportan información significativa.

En este caso, los primeros **3 componentes** cumplen la regla de Kaiser (PC1 = `r round(valores_propios[1], 2)`, PC2 = `r round(valores_propios[2], 2)`, PC3 = `r round(valores_propios[3], 2)`), mientras que PC4 (`r round(valores_propios[4], 2)`) ya cae por debajo de 1.

#### Gráfico de Sedimentación (Scree Plot)

El gráfico de sedimentación permite identificar visualmente el "codo" donde la varianza explicada por cada componente adicional comienza a estabilizarse.

```{r screeplot}
fviz_eig(compPrinc, addlabels = TRUE, ylim = c(0, 80))
fviz_eig(compPrinc, addlabels = TRUE, choice = c("eigenvalue"), ylim = c(0, 5))
```

El primer gráfico muestra el porcentaje de varianza explicada por cada componente, mientras que el segundo muestra los valores propios.
Se busca el punto donde la curva se estabiliza ("el codo"), lo que indica que los componentes adicionales ya no aportan información sustancial.

#### Porcentaje de Varianza Explicada

```{r varianza explicada}
summary(compPrinc)
```

Se busca retener suficientes componentes para explicar una proporción adecuada de la varianza total.

```{r tabla varianza}
varianza_tabla <- data.frame(
  Componente = paste0("PC", 1:length(valores_propios)),
  Valor_Propio = round(valores_propios, 4),
  Porcentaje_Varianza = round(valores_propios / sum(valores_propios) * 100, 2),
  Varianza_Acumulada = round(cumsum(valores_propios / sum(valores_propios) * 100), 2)
)
varianza_tabla
```

Con los primeros **3 componentes** (regla de Kaiser) se explica aproximadamente el **63.1%** de la varianza total.
Si se desea alcanzar al menos el **80%**, es necesario retener **6 componentes** (82.5% acumulado).
Existe un compromiso entre parsimonia (menos componentes, más fáciles de interpretar) y cobertura de varianza.
Para este análisis, se consideran los **3 primeros componentes** como los más relevantes por su interpretabilidad y por superar el umbral de Kaiser, aunque se reconoce que no capturan la totalidad de la variabilidad del dataset.

#### Prueba de Paralelismo (Horn's Parallel Analysis)

##### ¿Cómo funciona la Prueba de Paralelismo de Horn?

Se calculan los valores propios del PCA basado en los datos reales.
Se generan múltiples conjuntos de datos aleatorios con el mismo tamaño que los datos originales (mismo número de variables y observaciones).
Se realiza un PCA sobre los datos aleatorios y se extraen los valores propios esperados de cada componente.
Se comparan los valores propios reales con los esperados: Si un componente tiene un valor propio mayor que el de los datos simulados, significa que explica más varianza de la que se esperaría por azar, por lo que se retiene.
Si el valor propio es menor o igual al de los datos aleatorios, el componente no se retiene porque su explicación de varianza es insignificante.

En los resultados de esta prueba los valores simulados son los de la columna "Adjusted Eigenvalue" y los valores reales son "Unadjusted Eigenvalue".
Se retienen los componentes cuyo valor propio real sea mayor que el simulado.

```{r prueba de Horn}
paran(data_numeric, graph = TRUE)
```

### Carga Factorial Interpretativa

Se basa en la interpretación de los componentes.

En la siguiente gráfica se ilustra la calidad de la representación de las variables en las dos primeras dimensiones.

```{r grafico coseno}
fviz_pca_var(compPrinc, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE
)
```

**Interpretación del Gráfico de PCA:**

Representa la relación entre las variables originales proyectadas en el espacio de los dos primeros componentes principales (Dim1 y Dim2).
Vamos a analizarlo paso a paso.

1.  **Ejes del gráfico.** El Eje X (Dim1) representa el primer componente principal (PC1) y el Eje Y (Dim2) representa el segundo componente principal (PC2). Cada eje indica el porcentaje de varianza total que explica. En conjunto, los dos primeros componentes capturan una proporción de la variabilidad total de los datos.

2.  **Longitud de las Flechas (Vectores).** Cada flecha representa una variable original. La longitud de la flecha indica qué tan bien está representada la variable en el espacio de PC1 y PC2. Flechas largas indican que esas variables están bien representadas en los primeros dos componentes. Flechas cortas indican que la variable no está completamente explicada por PC1 y PC2 y puede necesitar más dimensiones para su interpretación.

3.  **Dirección de las Flechas.** Las variables con vectores apuntando en la misma dirección están correlacionadas positivamente. Las variables con vectores opuestos tienen una correlación negativa. Las variables con vectores perpendiculares (ángulo de 90°) están débilmente correlacionadas o no tienen relación.

4.  **Color de las Flechas (cos2 - Calidad de Representación).** El color indica el cos2, que mide la calidad de la representación de cada variable en el espacio de los componentes. Colores cálidos (rojo/naranja) representan variables bien explicadas por los primeros dos componentes (cos2 alto). Colores fríos (azul/verde) representan variables poco explicadas, lo que sugiere que necesitan más dimensiones para su correcta interpretación.

5.  **Relación con los Componentes Principales.** Se identifica qué variables tienen las cargas más altas en cada dimensión para interpretar conceptualmente qué representa cada componente.

### Biplot

El biplot combina la representación de las observaciones y las variables en el espacio de los componentes principales.

```{r biplot}
fviz_pca_biplot(compPrinc, repel = FALSE, 
                col.var = "#FC4E07",
                col.ind = "#00AFBB",
                alpha.ind = 0.1)
```

### Contribución de las variables a cada componente

Los siguientes gráficos muestran qué variables contribuyen más a cada una de las primeras tres dimensiones.
La línea roja discontinua representa la contribución esperada si todas las variables contribuyeran por igual.

```{r contribucion a las componentes}
fviz_contrib(compPrinc, choice = "var", axes = 1, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 2, top = 10)
fviz_contrib(compPrinc, choice = "var", axes = 3, top = 10)
```

### Calidad de representación (cos2) por variable y componente

El siguiente gráfico muestra la calidad de la representación de cada variable en cada componente.
Valores altos de cos2 indican que la variable está bien capturada por ese componente.

```{r cos2 corrplot}
var <- get_pca_var(compPrinc)
corrplot(var$cos2, is.corr = FALSE)
```

### Interpretación de las Componentes

Con base en los gráficos de contribución, las cargas factoriales y la calidad de representación, se interpretan los componentes retenidos.

```{r rotacion}
compPrinc$rotation
```

A partir de la matriz de rotación (loadings), se puede interpretar cada componente principal:

1.  **PC1 - Escala general de la película (38.2% de varianza).** Este componente presenta cargas positivas en prácticamente todas las variables: `actorsAmount` (0.39), `castWomenAmount` (0.36), `voteCount` (0.34), `budget` (0.34), `runtime` (0.33), `revenue` (0.32), `voteAvg` (0.32), `productionCoAmount` (0.28) y `genresAmount` (0.26). Es un componente de **tamaño o magnitud general**: películas con valores altos en PC1 son producciones grandes en todos los sentidos (mayor presupuesto, más ingresos, elencos más numerosos, mayor duración, más votos y mejor calificación). Las variables con menor peso son `popularity` (0.12) y `castMenAmount` (0.001), lo que indica que estas dos variables no se alinean con esta dimensión general. Es el patrón típico del primer componente en PCA, que captura la "escala" o "importancia" global del fenómeno.

2.  **PC2 - Producción internacional/artística vs. éxito comercial (13.9% de varianza).** Este componente contrasta dos perfiles de películas a través de cargas de signo opuesto. En el lado positivo: `productionCountriesAmount` (0.46), `castMenAmount` (0.39), `voteAvg` (0.30), `runtime` (0.25) — variables que describen producciones internacionales, con mayor duración y mejor evaluadas cualitativamente. En el lado negativo: `revenue` (-0.40), `budget` (-0.33), `voteCount` (-0.32) — variables que representan el éxito comercial medido en dinero y volumen de votos. Este componente diferencia entre **películas artísticas o de cine independiente/internacional** (rodadas en múltiples países, bien evaluadas pero con menor presupuesto) y **blockbusters comerciales** (alto presupuesto, altos ingresos, muchos votos pero no necesariamente mejor calificación).

3.  **PC3 - Estructura multinacional de producción (11.0% de varianza).** Dominado por cargas negativas fuertes en `castMenAmount` (-0.61) y `productionCountriesAmount` (-0.49), y una carga negativa moderada en `revenue` (-0.30). En el lado positivo, las cargas son más modestas: `productionCoAmount` (0.24), `genresAmount` (0.21). Este componente captura la dimensión de **producción multinacional con elencos masculinos grandes** en contraposición con **producciones con más compañías y diversidad de géneros**. La fuerte influencia de `castMenAmount` debe interpretarse con cautela dado los valores extremos observados en esta variable (media desproporcionada respecto a la mediana).

## Conclusiones

```{r resumen final}
varianza <- summary(compPrinc)
varianza
```

### Resumen de hallazgos

1.  **Viabilidad del PCA:** Las pruebas previas confirmaron la conveniencia de aplicar PCA. El determinante de la matriz de correlación cercano a 0 (`r round(det(rcor), 6)`) indica multicolinealidad. El índice KMO de `r round(resultado_kmo$MSA, 2)` (meritorio) y el rechazo contundente de la prueba de Bartlett (p-value = 0) respaldan la adecuación de los datos para el análisis factorial.

2.  **Dimensionalidad reducida:** Según la regla de Kaiser, se retienen **3 componentes principales** que explican el **63.1%** de la varianza total. Si se requiriera mayor cobertura (80%), serían necesarios 6 componentes. Las `r length(numeric_vars)` variables originales se resumen en 3 ejes decorrelacionados, facilitando el análisis.

3.  **Interpretabilidad de los componentes:**
    -   **PC1 (38.2%)** — **Escala general de la película**: captura la magnitud global de una producción (presupuesto, ingresos, elenco, duración, votos, calificación). Diferencia entre grandes producciones y películas pequeñas.
    -   **PC2 (13.9%)** — **Producción artística/internacional vs. comercial**: contrasta películas rodadas en múltiples países con buenas calificaciones pero menor presupuesto (perfil de cine independiente/artístico) contra blockbusters comerciales de alto presupuesto y altos ingresos.
    -   **PC3 (11.0%)** — **Estructura multinacional de producción**: captura la relación entre la cantidad de países de producción, la composición masculina del elenco y la diversidad de géneros/compañías.

4.  **Observaciones sobre la calidad de los datos:** La variable `castMenAmount` presenta valores extremos (media desproporcionada respecto a la mediana, con un máximo de 922,017) que afectan su comportamiento en el PCA. Esto se refleja en su MSA bajo (0.50) y su carga casi nula en PC1. Para futuros análisis, se recomienda investigar y tratar estos outliers antes de aplicar PCA.

5.  **Utilidad para modelos predictivos:** Al utilizar los componentes principales en lugar de las `r length(numeric_vars)` variables originales, se reduce la dimensionalidad, se eliminan problemas de multicolinealidad y se facilita la construcción de modelos de predicción futuros con variables decorrelacionadas.

6.  **Recomendaciones para CineVision Studios:**
    -   **Perfilamiento de películas:** Los tres componentes permiten ubicar cada película en un espacio tridimensional interpretable (escala general, perfil comercial vs. artístico, estructura de producción).
    -   **Segmentación estratégica:** CineVision Studios puede segmentar su catálogo según estos ejes para identificar nichos de mercado no explotados, por ejemplo, películas con alto potencial artístico (PC2 alto) pero baja visibilidad comercial.
    -   **Modelos predictivos:** Utilizar los scores de los componentes como variables de entrada para modelos de predicción de ingresos o popularidad, aprovechando que están decorrelacionados.
    -   **Limpieza de datos:** Antes de aplicar modelos avanzados, se recomienda revisar la variable `castMenAmount` y `productionCountriesAmount` para corregir posibles errores de registro.


# 4.1
## Justificación de la Selección: UMAP
Para esta última fase de la consultoría, se evaluaron las cuatro opciones propuestas (SVD, t-SNE, UMAP, ICA). Se descartó SVD por ser el motor matemático subyacente del PCA (ya realizado, resultaría redundante) e ICA porque las variables cinematográficas (presupuesto, ingresos, popularidad) están altamente entrelazadas y no provienen de "fuentes independientes" puras.

Entre t-SNE y UMAP, se seleccionó UMAP. A diferencia del PCA, que es lineal y puede superponer grupos en su proyección 2D, UMAP es un algoritmo de reducción de dimensionalidad no lineal excelente para separar visualmente "islas" de datos complejos. Se prefirió por encima de t-SNE debido a su superior eficiencia computacional y menor consumo de memoria RAM, lo cual es vital dada la alta carga de procesamiento que exige este volumen de datos. Esta técnica permitirá a CineVision Studios tener un mapa visual topológico claro para validar si los 4 perfiles comerciales descubiertos en el clustering realmente forman agrupaciones separadas y naturales.

```{r umap}
library(umap)
library(ggplot2)
library(dplyr)

cat("Ejecutando algoritmo UMAP...\n")

# Configuración de UMAP
umap_config <- umap.defaults
umap_config$random_state <- 666 

umap_res <- umap(movies_sample_scaled, config = umap_config)

# dataframe combinando las coordenadas UMAP y los Clústeres de K-Medias
umap_data <- data.frame(
  UMAP1 = umap_res$layout[, 1],
  UMAP2 = umap_res$layout[, 2],
  Cluster_KMeans = movies_sample_cluster$Cluster_KMeans
)

# grafico de dispersión no lineal
grafica_umap <- ggplot(umap_data, aes(x = UMAP1, y = UMAP2, color = Cluster_KMeans)) +
  geom_point(alpha = 0.7, size = 2.5) +
  theme_minimal() +
  labs(title = "Proyección UMAP: Visualización Topológica de Películas",
       subtitle = "Mapeo no lineal coloreado según los 4 perfiles comerciales (K-Medias)",
       x = "UMAP Dimensión 1",
       y = "UMAP Dimensión 2",
       color = "Clúster") +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "right")

print(grafica_umap)
```
# 4.2
El mapa visual generado por el algoritmo UMAP confirma claramente que los cuatro grupos de películas descubiertos antes están bien separados en la realidad. Se observa un núcleo principal que agrupa al cine comercial exitoso, el cual está muy alejado de las producciones amateur o cortometrajes que aparecen dispersos por su gran variedad de formatos. Por otro lado, las películas épicas y el cine independiente de nicho forman sus propias islas totalmente aisladas del resto. Para CineVision Studios, este gráfico funciona como un radar de riesgo muy útil para predecir de forma visual a qué modelo de negocio pertenecerá cualquier nuevo proyecto.

# 5.1
## Hallazgos, Conclusiones y Sugerencias
Agrupamiento (Clustering): El mercado no es uniforme, sino que se divide en cuatro perfiles claros. Se identificó un sólido núcleo de Cine Comercial Exitoso (duración estándar y alta rentabilidad) y una élite de Producciones Épicas (elencos masivos y duraciones extensas que logran la mejor aclamación del público). En contraste, existe una inmensa cantidad de proyectos amateur o de cortometrajes con impacto nulo, y un pequeño nicho de cine independiente de bajo presupuesto.

Reducción de Dimensionalidad (PCA): Se demostró que las 12 variables originales pueden resumirse eficientemente en 3 componentes principales que explican más del 63% de la variabilidad. Estos ejes representan: 1) La escala global de la película, 2) El balance entre arte/prestigio y éxito taquillero, y 3) La estructura de producción multinacional.

Reglas de Asociación (Apriori): El análisis reveló que la discretización cuidadosa y la eliminación de variables omnipresentes (como el idioma original en inglés) son pasos obligatorios. Al retirar el ruido estadístico, emergieron patrones de asociación muy fuertes entre rangos de presupuesto, volumen de votos y niveles de popularidad.

Mapeo Topológico (UMAP): Validó visualmente las matemáticas del clustering. Demostró que las películas de nicho y las súper-producciones forman "islas" completamente separadas del núcleo comercial, confirmando que operan bajo modelos de negocio estadísticamente distintos.

## Sugerencias para CineVision Studios:
Con base en los patrones descubiertos, se proponen las siguientes acciones clave para el estudio:
* Apostar por el cine comercial estándar: Dirigir la mayor parte de la inversión a películas de formato tradicional (alrededor de 100 minutos y presupuesto moderado), ya que demostraron ser la opción más segura, popular y rentable.
* Invertir selectivamente en prestigio: Producir solo uno o dos proyectos épicos al año (de gran elenco y larga duración). Aunque son difíciles de hacer, aseguran las calificaciones más altas del público y dan prestigio al estudio.
* Usar el mapa visual como filtro de riesgo: Antes de aprobar y financiar un nuevo proyecto, se debe comparar con el mapa generado para predecir rápidamente si será un éxito comercial o si corre el riesgo de generar pérdidas.
* ambiar la distribución del cine independiente: Las películas de muy bajo presupuesto y de nicho no deben gastar dinero en publicidad masiva para cines. Su estrategia debe ser ir directamente a festivales especializados o plataformas de streaming.
